{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspecting bias due to systematic modeling\n",
    "\n",
    "In this notebook toy datasets are generated from the Asimov dataset accounting for statistical and systematic uncertainties in the model.  Each toy dataset is fit as in the nominal analysis and the estimated model parameters are compared to their input values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T22:28:30.601905Z",
     "start_time": "2020-04-29T22:28:30.453827Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/naodell/work/wbr/analysis\n",
      "{\n",
      "  \"shell_port\": 53845,\n",
      "  \"iopub_port\": 48505,\n",
      "  \"stdin_port\": 55759,\n",
      "  \"control_port\": 39903,\n",
      "  \"hb_port\": 52805,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"key\": \"46eafc31-724672f45855fc2d100912b3\",\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"kernel_name\": \"\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-e2150248-9340-4035-a03c-e3f32e7c914c.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "## imports and configuration\n",
    "%cd '/home/naodell/work/wbr/analysis'\n",
    "#%load_ext autoreload\n",
    "\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from scipy.optimize import minimize, basinhopping\n",
    "from scipy.stats import norm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import scripts.plot_tools as pt\n",
    "import scripts.fit_helpers as fh\n",
    "from nllfit.nllfitter import ScanParameters\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "rc_params = {\n",
    "             'figure.figsize': (10, 10),\n",
    "             'axes.labelsize': 20,\n",
    "             'axes.facecolor': 'white',\n",
    "             'axes.titlesize':'x-large',\n",
    "             'legend.fontsize': 20,\n",
    "             'xtick.labelsize':20,\n",
    "             'ytick.labelsize':20,\n",
    "             'font.size':18,\n",
    "             'font.sans-serif':['Arial', 'sans-serif'],\n",
    "             'mathtext.sf':'Arial',\n",
    "             'lines.markersize':8.,\n",
    "             'lines.linewidth':2.5,\n",
    "            }\n",
    "matplotlib.rcParams.update(rc_params)\n",
    "\n",
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T22:28:35.248388Z",
     "start_time": "2020-05-11T22:28:25.759934Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# configure, get the input data, and do any additional processing that is needed\n",
    "input_dir  = f'local_data/templates/test_08242020/'\n",
    "processes = ['ttbar', 't', 'ww', 'wjets', 'zjets_alt', 'gjets', 'diboson', 'fakes'] \n",
    "selections = [\n",
    "    'ee', \n",
    "    'mumu',  \n",
    "    'emu', \n",
    "    'mutau', \n",
    "    'etau', \n",
    "    'mujet', \n",
    "    'ejet'\n",
    "   ]\n",
    "plot_labels = fh.fancy_labels\n",
    "\n",
    "# initialize fit data\n",
    "fit_data = fh.FitData(input_dir, selections, processes, \n",
    "                      param_file  = 'data/model_parameters_alt.csv',\n",
    "                      process_cut = 0.01\n",
    "                     )\n",
    "params   = fit_data._parameters\n",
    "params_pre = fit_data.get_params_init().values.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T22:28:35.599551Z",
     "start_time": "2020-04-29T22:28:35.595826Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# initialize category veto list\n",
    "fit_data.veto_list = [\n",
    "    # baseline\n",
    "    #'ee_cat_gt2_eq1_b', 'ee_cat_gt2_gt2_b', \n",
    "    #'mumu_cat_gt2_eq1_b', 'mumu_cat_gt2_gt2_b', \n",
    "    #'emu_cat_gt2_eq1_a', 'emu_cat_gt2_gt2_a', \n",
    "    #'etau_cat_eq2_eq1', 'etau_cat_gt3_eq1', 'etau_cat_eq2_gt2', 'etau_cat_gt3_gt2', \n",
    "    #'mutau_cat_eq2_eq1', 'mutau_cat_gt3_eq1', 'mutau_cat_eq2_gt2', 'mutau_cat_gt3_gt2', \n",
    "    #'ejet_cat_gt4_eq1', 'ejet_cat_gt4_gt2',\n",
    "    #'mujet_cat_gt4_eq1', 'mujet_cat_gt4_gt2', \n",
    "    'ejet_cat_eq3_gt2', 'mujet_cat_eq3_gt2',\n",
    "    \n",
    "    # e/mu DY CR\n",
    "    'ee_cat_gt2_eq0',  'mumu_cat_gt2_eq0', \n",
    "    \n",
    "    # e+mu additional ttbar\n",
    "    'emu_cat_gt2_eq0', 'emu_cat_eq1_eq0_a', 'emu_cat_eq1_eq1_a', \n",
    "    \n",
    "    # e+mu WW\n",
    "    'emu_cat_eq0_eq0_a', \n",
    "    \n",
    "    # e/mu+tau additional CR\n",
    "    'mutau_cat_eq0_eq0', 'mutau_cat_eq1_eq0', \n",
    "    'mutau_cat_gt2_eq0', 'mutau_cat_eq1_eq1', \n",
    "    'etau_cat_eq0_eq0', 'etau_cat_eq1_eq0', \n",
    "    'etau_cat_gt2_eq0', 'etau_cat_eq1_eq1', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T22:28:35.613836Z",
     "start_time": "2020-04-29T22:28:35.600688Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# generate scan points\n",
    "beta_scan_vals = ScanParameters(['beta_e', 'beta_mu', 'beta_tau'], \n",
    "                                [(0.104, 0.118), (0.104, 0.118), (0.104, 0.118)], \n",
    "                                [5, 5, 5]\n",
    "                                )\n",
    "scan_vals = np.array(beta_scan_vals.get_scan_vals()[0])\n",
    "beta_h = np.transpose([1 - np.sum(scan_vals, axis=1)])\n",
    "scan_vals = np.hstack((scan_vals, beta_h, np.outer(np.ones(scan_vals.shape[0]), params_pre[4:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T22:28:35.630391Z",
     "start_time": "2020-04-29T22:28:35.614957Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# initialize objective and its jacobian\n",
    "fobj = partial(fit_data.objective,\n",
    "               data = None,\n",
    "               do_bb_lite = False,\n",
    "               no_shape = False,\n",
    "               lu_test = 2\n",
    "              )\n",
    "\n",
    "fobj_jac = partial(fit_data.objective_jacobian,\n",
    "                   data = None,\n",
    "                   do_bb_lite = False,\n",
    "                   no_shape = False,\n",
    "                   lu_test = 2\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T23:12:09.128547Z",
     "start_time": "2020-04-29T22:28:35.633385Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec52fbc2e43d49978edfe386234017ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.002215\n",
      "         Iterations: 34\n",
      "         Function evaluations: 219\n",
      "         Gradient evaluations: 202\n",
      "False 1143.76346151526 996.0977759519109 0.00221511690732286\n",
      " scan vals:  [0.104 0.104 0.104 0.688]\n",
      " fit vals: [0.104 0.104 0.104 0.688]\n",
      "\n",
      " % diff vals: [ 3.1895e-05  4.7751e-05  2.0094e-04 -4.2413e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.001461\n",
      "         Iterations: 31\n",
      "         Function evaluations: 119\n",
      "         Gradient evaluations: 107\n",
      "False 1143.76346151526 940.125249690619 0.0014614885249579538\n",
      " scan vals:  [0.104  0.104  0.1075 0.6845]\n",
      " fit vals: [0.104  0.104  0.1075 0.6845]\n",
      "\n",
      " % diff vals: [ 4.6768e-05  6.9817e-05 -4.4370e-06 -1.7016e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001785\n",
      "         Iterations: 32\n",
      "         Function evaluations: 48\n",
      "         Gradient evaluations: 48\n",
      "True 1143.76346151526 906.5004213125059 0.0017848426427543426\n",
      " scan vals:  [0.104 0.104 0.111 0.681]\n",
      " fit vals: [0.104 0.104 0.111 0.681]\n",
      "\n",
      " % diff vals: [ 6.1565e-05  9.2640e-05 -2.0321e-04  9.5732e-06]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.003185\n",
      "         Iterations: 31\n",
      "         Function evaluations: 186\n",
      "         Gradient evaluations: 172\n",
      "False 1143.76346151526 894.8414222430204 0.0031851713123955696\n",
      " scan vals:  [0.104  0.104  0.1145 0.6775]\n",
      " fit vals: [0.104  0.104  0.1145 0.6775]\n",
      "\n",
      " % diff vals: [ 7.7061e-05  1.1628e-04 -3.9580e-04  3.7212e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.005662\n",
      "         Iterations: 31\n",
      "         Function evaluations: 111\n",
      "         Gradient evaluations: 100\n",
      "False 1143.76346151526 904.8002566585046 0.005662476640629999\n",
      " scan vals:  [0.104 0.104 0.118 0.674]\n",
      " fit vals: [0.104 0.104 0.118 0.674]\n",
      "\n",
      " % diff vals: [ 9.3458e-05  1.4055e-04 -5.8345e-04  6.6038e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001461\n",
      "         Iterations: 29\n",
      "         Function evaluations: 42\n",
      "         Gradient evaluations: 42\n",
      "True 1143.76346151526 927.3381305606364 0.0014614673422473068\n",
      " scan vals:  [0.104  0.1075 0.104  0.6845]\n",
      " fit vals: [0.104  0.1075 0.104  0.6845]\n",
      "\n",
      " % diff vals: [ 1.7642e-05 -2.0320e-06  2.1570e-04 -3.5133e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000735\n",
      "         Iterations: 27\n",
      "         Function evaluations: 78\n",
      "         Gradient evaluations: 68\n",
      "False 1143.76346151526 902.9678777429199 0.0007346512700709577\n",
      " scan vals:  [0.104  0.1075 0.1075 0.681 ]\n",
      " fit vals: [0.104  0.1075 0.1075 0.681 ]\n",
      "\n",
      " % diff vals: [ 3.4458e-05  2.1208e-05  1.2012e-05 -1.0506e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.001085\n",
      "         Iterations: 28\n",
      "         Function evaluations: 124\n",
      "         Gradient evaluations: 113\n",
      "False 1143.76346151526 900.953082239136 0.001084816623959541\n",
      " scan vals:  [0.104  0.1075 0.111  0.6775]\n",
      " fit vals: [0.104  0.1075 0.111  0.6775]\n",
      "\n",
      " % diff vals: [ 4.7295e-05  4.1589e-05 -1.8155e-04  1.5886e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002512\n",
      "         Iterations: 28\n",
      "         Function evaluations: 43\n",
      "         Gradient evaluations: 43\n",
      "True 1143.76346151526 920.9209797919511 0.00251196001171293\n",
      " scan vals:  [0.104  0.1075 0.1145 0.674 ]\n",
      " fit vals: [0.104  0.1075 0.1145 0.674 ]\n",
      "\n",
      " % diff vals: [ 6.1545e-05  6.4500e-05 -3.7138e-04  4.3306e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.005016\n",
      "         Iterations: 28\n",
      "         Function evaluations: 42\n",
      "         Gradient evaluations: 42\n",
      "True 1143.76346151526 962.531260832459 0.0050160804125698654\n",
      " scan vals:  [0.104  0.1075 0.118  0.6705]\n",
      " fit vals: [0.104  0.1075 0.118  0.6705]\n",
      "\n",
      " % diff vals: [ 7.7167e-05  8.8118e-05 -5.5522e-04  7.1615e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.001785\n",
      "         Iterations: 28\n",
      "         Function evaluations: 120\n",
      "         Gradient evaluations: 109\n",
      "False 1143.76346151526 1573.3802878219562 0.00178484773739026\n",
      " scan vals:  [0.104 0.111 0.104 0.681]\n",
      " fit vals: [0.104 0.111 0.104 0.681]\n",
      "\n",
      " % diff vals: [ 3.3195e-06 -4.9395e-05  2.3143e-04 -2.7799e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.001085\n",
      "         Iterations: 29\n",
      "         Function evaluations: 113\n",
      "         Gradient evaluations: 102\n",
      "False 1143.76346151526 1578.1651021720695 0.0010848438794848066\n",
      " scan vals:  [0.104  0.111  0.1075 0.6775]\n",
      " fit vals: [0.104  0.111  0.1075 0.6775]\n",
      "\n",
      " % diff vals: [ 1.7416e-05 -2.8209e-05  3.2358e-05 -3.1862e-06]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001462\n",
      "         Iterations: 29\n",
      "         Function evaluations: 43\n",
      "         Gradient evaluations: 43\n",
      "True 1143.76346151526 1605.3593891428297 0.0014618225007199646\n",
      " scan vals:  [0.104 0.111 0.111 0.674]\n",
      " fit vals: [0.104 0.111 0.111 0.674]\n",
      "\n",
      " % diff vals: [ 3.1780e-05 -6.5498e-06 -1.6020e-04  2.2559e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.002916\n",
      "         Iterations: 30\n",
      "         Function evaluations: 164\n",
      "         Gradient evaluations: 149\n",
      "False 1143.76346151526 1654.5971794760853 0.0029157802492004326\n",
      " scan vals:  [0.104  0.111  0.1145 0.6705]\n",
      " fit vals: [0.104  0.111  0.1145 0.6705]\n",
      "\n",
      " % diff vals: [ 4.6639e-05  1.5755e-05 -3.4684e-04  4.9386e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.005447\n",
      "         Iterations: 30\n",
      "         Function evaluations: 157\n",
      "         Gradient evaluations: 144\n",
      "False 1143.76346151526 1725.543724569619 0.005446715124952548\n",
      " scan vals:  [0.104 0.111 0.118 0.667]\n",
      " fit vals: [0.104 0.111 0.118 0.667]\n",
      "\n",
      " % diff vals: [ 6.1913e-05  3.8659e-05 -5.2792e-04  7.7307e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.003185\n",
      "         Iterations: 31\n",
      "         Function evaluations: 121\n",
      "         Gradient evaluations: 109\n",
      "False 1143.76346151526 2901.85341344476 0.0031852591857929827\n",
      " scan vals:  [0.104  0.1145 0.104  0.6775]\n",
      " fit vals: [0.104  0.1145 0.104  0.6775]\n",
      "\n",
      " % diff vals: [-1.0189e-05 -9.4220e-05  2.4872e-04 -2.0693e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002512\n",
      "         Iterations: 33\n",
      "         Function evaluations: 46\n",
      "         Gradient evaluations: 46\n",
      "True 1143.76346151526 2933.610389757026 0.002512067592328257\n",
      " scan vals:  [0.104  0.1145 0.1075 0.674 ]\n",
      " fit vals: [0.104  0.1145 0.1075 0.674 ]\n",
      "\n",
      " % diff vals: [ 3.6014e-06 -7.3154e-05  5.1538e-05  3.6515e-06]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.002916\n",
      "         Iterations: 34\n",
      "         Function evaluations: 239\n",
      "         Gradient evaluations: 227\n",
      "False 1143.76346151526 2987.8701617114666 0.002915858519084841\n",
      " scan vals:  [0.104  0.1145 0.111  0.6705]\n",
      " fit vals: [0.104  0.1145 0.111  0.6705]\n",
      "\n",
      " % diff vals: [ 1.7664e-05 -5.2098e-05 -1.3811e-04  2.9020e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.004397\n",
      "         Iterations: 31\n",
      "         Function evaluations: 192\n",
      "         Gradient evaluations: 181\n",
      "False 1143.76346151526 3064.2715303851583 0.00439663103175158\n",
      " scan vals:  [0.104  0.1145 0.1145 0.667 ]\n",
      " fit vals: [0.104  0.1145 0.1145 0.667 ]\n",
      "\n",
      " % diff vals: [ 3.1599e-05 -3.1645e-05 -3.2037e-04  5.5500e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.006954\n",
      "         Iterations: 31\n",
      "         Function evaluations: 128\n",
      "         Gradient evaluations: 116\n",
      "False 1143.76346151526 3162.483450913624 0.006954381971638615\n",
      " scan vals:  [0.104  0.1145 0.118  0.6635]\n",
      " fit vals: [0.104  0.1145 0.118  0.6635]\n",
      "\n",
      " % diff vals: [ 4.6868e-05 -9.0433e-06 -4.9878e-04  8.2918e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.005663\n",
      "         Iterations: 32\n",
      "         Function evaluations: 115\n",
      "         Gradient evaluations: 105\n",
      "False 1143.76346151526 4884.790869280052 0.005662702100768109\n",
      " scan vals:  [0.104 0.118 0.104 0.674]\n",
      " fit vals: [0.104 0.118 0.104 0.674]\n",
      "\n",
      " % diff vals: [-2.3036e-05 -1.3703e-04  2.6368e-04 -1.3141e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.005016\n",
      "         Iterations: 33\n",
      "         Function evaluations: 48\n",
      "         Gradient evaluations: 48\n",
      "True 1143.76346151526 4941.5555039488545 0.005016321148988558\n",
      " scan vals:  [0.104  0.118  0.1075 0.6705]\n",
      " fit vals: [0.104  0.118  0.1075 0.6705]\n",
      "\n",
      " % diff vals: [-9.6847e-06 -1.1561e-04  7.1018e-05  1.0461e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.005447\n",
      "         Iterations: 32\n",
      "         Function evaluations: 123\n",
      "         Gradient evaluations: 113\n",
      "False 1143.76346151526 5020.949728169168 0.005446925554233915\n",
      " scan vals:  [0.104 0.118 0.111 0.667]\n",
      " fit vals: [0.104 0.118 0.111 0.667]\n",
      "\n",
      " % diff vals: [ 3.8624e-06 -9.7540e-05 -1.1511e-04  3.5808e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.006955\n",
      "         Iterations: 33\n",
      "         Function evaluations: 171\n",
      "         Gradient evaluations: 158\n",
      "False 1143.76346151526 5122.615334448435 0.00695451327548885\n",
      " scan vals:  [0.104  0.118  0.1145 0.6635]\n",
      " fit vals: [0.104  0.118  0.1145 0.6635]\n",
      "\n",
      " % diff vals: [ 1.8134e-05 -7.6045e-05 -2.9562e-04  6.1695e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.009539\n",
      "         Iterations: 33\n",
      "         Function evaluations: 49\n",
      "         Gradient evaluations: 49\n",
      "True 1143.76346151526 5246.2233556772235 0.009539079745462808\n",
      " scan vals:  [0.104 0.118 0.118 0.66 ]\n",
      " fit vals: [0.104 0.118 0.118 0.66 ]\n",
      "\n",
      " % diff vals: [ 3.3205e-05 -5.2031e-05 -4.7303e-04  8.8640e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.001461\n",
      "         Iterations: 31\n",
      "         Function evaluations: 129\n",
      "         Gradient evaluations: 118\n",
      "False 1143.76346151526 1069.6025531282748 0.0014614649175834066\n",
      " scan vals:  [0.1075 0.104  0.104  0.6845]\n",
      " fit vals: [0.1075 0.104  0.104  0.6845]\n",
      "\n",
      " % diff vals: [ 3.7006e-06  3.3763e-05  2.0911e-04 -3.7481e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000735\n",
      "         Iterations: 29\n",
      "         Function evaluations: 142\n",
      "         Gradient evaluations: 131\n",
      "False 1143.76346151526 1035.002429561204 0.0007346470671304935\n",
      " scan vals:  [0.1075 0.104  0.1075 0.681 ]\n",
      " fit vals: [0.1075 0.104  0.1075 0.681 ]\n",
      "\n",
      " % diff vals: [ 1.7580e-05  5.5300e-05  6.2148e-06 -1.2201e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.001085\n",
      "         Iterations: 30\n",
      "         Function evaluations: 223\n",
      "         Gradient evaluations: 210\n",
      "False 1143.76346151526 1022.8367731589458 0.0010848099358749391\n",
      " scan vals:  [0.1075 0.104  0.111  0.6775]\n",
      " fit vals: [0.1075 0.104  0.111  0.6775]\n",
      "\n",
      " % diff vals: [ 3.2149e-05  7.7751e-05 -1.9057e-04  1.4186e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.002512\n",
      "         Iterations: 28\n",
      "         Function evaluations: 106\n",
      "         Gradient evaluations: 96\n",
      "False 1143.76346151526 1032.7265688710927 0.0025119505712254027\n",
      " scan vals:  [0.1075 0.104  0.1145 0.674 ]\n",
      " fit vals: [0.1075 0.104  0.1145 0.674 ]\n",
      "\n",
      " % diff vals: [ 4.6896e-05  1.0043e-04 -3.8094e-04  4.1739e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.005016\n",
      "         Iterations: 30\n",
      "         Function evaluations: 94\n",
      "         Gradient evaluations: 82\n",
      "False 1143.76346151526 1064.3259795743086 0.005016066239344853\n",
      " scan vals:  [0.1075 0.104  0.118  0.6705]\n",
      " fit vals: [0.1075 0.104  0.118  0.6705]\n",
      "\n",
      " % diff vals: [ 6.2700e-05  1.2474e-04 -5.6597e-04  7.0204e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000735\n",
      "         Iterations: 27\n",
      "         Function evaluations: 49\n",
      "         Gradient evaluations: 49\n",
      "True 1143.76346151526 1026.89862287063 0.000734617630204791\n",
      " scan vals:  [0.1075 0.1075 0.104  0.681 ]\n",
      " fit vals: [0.1075 0.1075 0.104  0.681 ]\n",
      "\n",
      " % diff vals: [-9.7414e-06 -1.5428e-05  2.2373e-04 -3.0195e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000035\n",
      "         Iterations: 28\n",
      "         Function evaluations: 87\n",
      "         Gradient evaluations: 86\n",
      "True 1143.76346151526 1024.1999988473926 3.4611254679620185e-05\n",
      " scan vals:  [0.1075 0.1075 0.1075 0.6775]\n",
      " fit vals: [0.1075 0.1075 0.1075 0.6775]\n",
      "\n",
      " % diff vals: [ 3.8957e-06  5.5816e-06  2.3943e-05 -5.3027e-06]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000412\n",
      "         Iterations: 27\n",
      "         Function evaluations: 163\n",
      "         Gradient evaluations: 149\n",
      "False 1143.76346151526 1043.9423699748857 0.0004115864581024761\n",
      " scan vals:  [0.1075 0.1075 0.111  0.674 ]\n",
      " fit vals: [0.1075 0.1075 0.111  0.674 ]\n",
      "\n",
      " % diff vals: [ 1.8480e-05  2.6449e-05 -1.6987e-04  2.0809e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001866\n",
      "         Iterations: 28\n",
      "         Function evaluations: 46\n",
      "         Gradient evaluations: 46\n",
      "True 1143.76346151526 1085.7558521357892 0.001865541083389521\n",
      " scan vals:  [0.1075 0.1075 0.1145 0.6705]\n",
      " fit vals: [0.1075 0.1075 0.1145 0.6705]\n",
      "\n",
      " % diff vals: [ 3.2809e-05  5.0338e-05 -3.5740e-04  4.7702e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.004396\n",
      "         Iterations: 27\n",
      "         Function evaluations: 144\n",
      "         Gradient evaluations: 131\n",
      "False 1143.76346151526 1149.3023144888775 0.0043964724674462\n",
      " scan vals:  [0.1075 0.1075 0.118  0.667 ]\n",
      " fit vals: [0.1075 0.1075 0.118  0.667 ]\n",
      "\n",
      " % diff vals: [ 4.8295e-05  7.3737e-05 -5.3875e-04  7.5642e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001085\n",
      "         Iterations: 28\n",
      "         Function evaluations: 40\n",
      "         Gradient evaluations: 40\n",
      "True 1143.76346151526 1699.8617860502127 0.001084800813289378\n",
      " scan vals:  [0.1075 0.111  0.104  0.6775]\n",
      " fit vals: [0.1075 0.111  0.104  0.6775]\n",
      "\n",
      " % diff vals: [-2.2870e-05 -6.1626e-05  2.3933e-04 -2.3013e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000412\n",
      "         Iterations: 29\n",
      "         Function evaluations: 126\n",
      "         Gradient evaluations: 115\n",
      "False 1143.76346151526 1726.6154121538675 0.000411604918444015\n",
      " scan vals:  [0.1075 0.111  0.1075 0.674 ]\n",
      " fit vals: [0.1075 0.111  0.1075 0.674 ]\n",
      "\n",
      " % diff vals: [-9.1801e-06 -4.0670e-05  4.1929e-05  1.4743e-06]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000815\n",
      "         Iterations: 27\n",
      "         Function evaluations: 99\n",
      "         Gradient evaluations: 88\n",
      "False 1143.76346151526 1775.8627628736012 0.0008153945263924649\n",
      " scan vals:  [0.1075 0.111  0.111  0.6705]\n",
      " fit vals: [0.1075 0.111  0.111  0.6705]\n",
      "\n",
      " % diff vals: [ 5.3564e-06 -1.6595e-05 -1.4992e-04  2.6708e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002296\n",
      "         Iterations: 30\n",
      "         Function evaluations: 45\n",
      "         Gradient evaluations: 45\n",
      "True 1143.76346151526 1847.2407846615788 0.0022961633732816763\n",
      " scan vals:  [0.1075 0.111  0.1145 0.667 ]\n",
      " fit vals: [0.1075 0.111  0.1145 0.667 ]\n",
      "\n",
      " % diff vals: [ 1.8975e-05  2.6014e-06 -3.3332e-04  5.3727e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.004854\n",
      "         Iterations: 27\n",
      "         Function evaluations: 103\n",
      "         Gradient evaluations: 91\n",
      "False 1143.76346151526 1940.41693634213 0.004853909296658079\n",
      " scan vals:  [0.1075 0.111  0.118  0.6635]\n",
      " fit vals: [0.1075 0.111  0.118  0.6635]\n",
      "\n",
      " % diff vals: [ 3.3897e-05  2.5138e-05 -5.1782e-04  8.2392e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.002512\n",
      "         Iterations: 31\n",
      "         Function evaluations: 113\n",
      "         Gradient evaluations: 101\n",
      "False 1143.76346151526 3055.942055204228 0.0025120140847345106\n",
      " scan vals:  [0.1075 0.1145 0.104  0.674 ]\n",
      " fit vals: [0.1075 0.1145 0.104  0.674 ]\n",
      "\n",
      " % diff vals: [-3.5391e-05 -1.0516e-04  2.5557e-04 -1.5926e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.001866\n",
      "         Iterations: 33\n",
      "         Function evaluations: 210\n",
      "         Gradient evaluations: 195\n",
      "False 1143.76346151526 3109.962649902084 0.001865631236766376\n",
      " scan vals:  [0.1075 0.1145 0.1075 0.6705]\n",
      " fit vals: [0.1075 0.1145 0.1075 0.6705]\n",
      "\n",
      " % diff vals: [-2.3025e-05 -8.6164e-05  6.1561e-05  8.5350e-06]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002296\n",
      "         Iterations: 32\n",
      "         Function evaluations: 47\n",
      "         Gradient evaluations: 47\n",
      "True 1143.76346151526 3186.56899096985 0.0022962327066380463\n",
      " scan vals:  [0.1075 0.1145 0.111  0.667 ]\n",
      " fit vals: [0.1075 0.1145 0.111  0.667 ]\n",
      "\n",
      " % diff vals: [-8.5531e-06 -6.4117e-05 -1.2674e-04  3.3476e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.003804\n",
      "         Iterations: 31\n",
      "         Function evaluations: 158\n",
      "         Gradient evaluations: 145\n",
      "False 1143.76346151526 3285.4028378150138 0.0038038164229191648\n",
      " scan vals:  [0.1075 0.1145 0.1145 0.6635]\n",
      " fit vals: [0.1075 0.1145 0.1145 0.6635]\n",
      "\n",
      " % diff vals: [ 4.6901e-06 -4.3819e-05 -3.0753e-04  5.9872e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.006388\n",
      "         Iterations: 31\n",
      "         Function evaluations: 209\n",
      "         Gradient evaluations: 197\n",
      "False 1143.76346151526 3406.13538851869 0.006388378218624724\n",
      " scan vals:  [0.1075 0.1145 0.118  0.66  ]\n",
      " fit vals: [0.1075 0.1145 0.118  0.66  ]\n",
      "\n",
      " % diff vals: [ 2.0218e-05 -2.0427e-05 -4.8566e-04  8.7080e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.005016\n",
      "         Iterations: 32\n",
      "         Function evaluations: 130\n",
      "         Gradient evaluations: 119\n",
      "False 1143.76346151526 5067.014667236158 0.005016258543562914\n",
      " scan vals:  [0.1075 0.118  0.104  0.6705]\n",
      " fit vals: [0.1075 0.118  0.104  0.6705]\n",
      "\n",
      " % diff vals: [-4.8224e-05 -1.4798e-04  2.6983e-04 -8.0791e-06]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.004397\n",
      "         Iterations: 33\n",
      "         Function evaluations: 203\n",
      "         Gradient evaluations: 189\n",
      "False 1143.76346151526 5146.335180240738 0.0043966869851401235\n",
      " scan vals:  [0.1075 0.118  0.1075 0.667 ]\n",
      " fit vals: [0.1075 0.118  0.1075 0.667 ]\n",
      "\n",
      " % diff vals: [-3.4566e-05 -1.2654e-04  8.0285e-05  1.5018e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.004854\n",
      "         Iterations: 31\n",
      "         Function evaluations: 135\n",
      "         Gradient evaluations: 124\n",
      "False 1143.76346151526 5248.3669471786925 0.00485410123977502\n",
      " scan vals:  [0.1075 0.118  0.111  0.6635]\n",
      " fit vals: [0.1075 0.118  0.111  0.6635]\n",
      "\n",
      " % diff vals: [-2.1252e-05 -1.0658e-04 -1.0500e-04  3.9963e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.006388\n",
      "         Iterations: 33\n",
      "         Function evaluations: 191\n",
      "         Gradient evaluations: 178\n",
      "False 1143.76346151526 5372.754766965096 0.0063884992007709595\n",
      " scan vals:  [0.1075 0.118  0.1145 0.66  ]\n",
      " fit vals: [0.1075 0.118  0.1145 0.66  ]\n",
      "\n",
      " % diff vals: [-7.3414e-06 -8.5405e-05 -2.8437e-04  6.5797e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.009000\n",
      "         Iterations: 32\n",
      "         Function evaluations: 141\n",
      "         Gradient evaluations: 130\n",
      "False 1143.76346151526 5519.1719562610615 0.0089998773057895\n",
      " scan vals:  [0.1075 0.118  0.118  0.6565]\n",
      " fit vals: [0.1075 0.118  0.118  0.6565]\n",
      "\n",
      " % diff vals: [ 7.0574e-06 -6.3778e-05 -4.5889e-04  9.2787e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.001785\n",
      "         Iterations: 30\n",
      "         Function evaluations: 113\n",
      "         Gradient evaluations: 101\n",
      "False 1143.76346151526 1647.9701848377424 0.0017848500076939593\n",
      " scan vals:  [0.111 0.104 0.104 0.681]\n",
      " fit vals: [0.111 0.104 0.104 0.681]\n",
      "\n",
      " % diff vals: [-2.4603e-05  1.8724e-05  2.1814e-04 -3.2163e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001085\n",
      "         Iterations: 29\n",
      "         Function evaluations: 40\n",
      "         Gradient evaluations: 40\n",
      "True 1143.76346151526 1633.1847775097738 0.0010848430507346034\n",
      " scan vals:  [0.111  0.104  0.1075 0.6775]\n",
      " fit vals: [0.111  0.104  0.1075 0.6775]\n",
      "\n",
      " % diff vals: [-1.0975e-05  4.0227e-05  1.6896e-05 -7.0577e-06]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.001462\n",
      "         Iterations: 32\n",
      "         Function evaluations: 112\n",
      "         Gradient evaluations: 100\n",
      "False 1143.76346151526 1640.9408377138914 0.0014618155017464137\n",
      " scan vals:  [0.111 0.104 0.111 0.674]\n",
      " fit vals: [0.111 0.104 0.111 0.674]\n",
      "\n",
      " % diff vals: [ 3.1233e-06  6.2537e-05 -1.7785e-04  1.9126e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002916\n",
      "         Iterations: 31\n",
      "         Function evaluations: 47\n",
      "         Gradient evaluations: 47\n",
      "True 1143.76346151526 1670.8610260106018 0.0029157682859137345\n",
      " scan vals:  [0.111  0.104  0.1145 0.6705]\n",
      " fit vals: [0.111  0.104  0.1145 0.6705]\n",
      "\n",
      " % diff vals: [ 1.7661e-05  8.5494e-05 -3.6647e-04  4.6396e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.005447\n",
      "         Iterations: 30\n",
      "         Function evaluations: 113\n",
      "         Gradient evaluations: 112\n",
      "True 1143.76346151526 1722.60059394101 0.00544669566294561\n",
      " scan vals:  [0.111 0.104 0.118 0.667]\n",
      " fit vals: [0.111 0.104 0.118 0.667]\n",
      "\n",
      " % diff vals: [ 3.2732e-05  1.0919e-04 -5.4953e-04  7.4745e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.001085\n",
      "         Iterations: 28\n",
      "         Function evaluations: 108\n",
      "         Gradient evaluations: 97\n",
      "False 1143.76346151526 1632.0795324969797 0.0010848053385885353\n",
      " scan vals:  [0.111  0.1075 0.104  0.6775]\n",
      " fit vals: [0.111  0.1075 0.104  0.6775]\n",
      "\n",
      " % diff vals: [-3.7170e-05 -2.6708e-05  2.3206e-04 -2.5295e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000412\n",
      "         Iterations: 29\n",
      "         Function evaluations: 42\n",
      "         Gradient evaluations: 42\n",
      "True 1143.76346151526 1649.4924878184931 0.0004116087166773415\n",
      " scan vals:  [0.111  0.1075 0.1075 0.674 ]\n",
      " fit vals: [0.111  0.1075 0.1075 0.674 ]\n",
      "\n",
      " % diff vals: [-2.3739e-05 -8.0887e-06  3.4391e-05 -2.8562e-07]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.000815\n",
      "         Iterations: 27\n",
      "         Function evaluations: 96\n",
      "         Gradient evaluations: 84\n",
      "False 1143.76346151526 1689.4520404274128 0.0008153936334293645\n",
      " scan vals:  [0.111  0.1075 0.111  0.6705]\n",
      " fit vals: [0.111  0.1075 0.111  0.6705]\n",
      "\n",
      " % diff vals: [-9.6133e-06  1.3849e-05 -1.5615e-04  2.5220e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.002296\n",
      "         Iterations: 25\n",
      "         Function evaluations: 122\n",
      "         Gradient evaluations: 110\n",
      "False 1143.76346151526 1751.5900199974703 0.002296159874556117\n",
      " scan vals:  [0.111  0.1075 0.1145 0.667 ]\n",
      " fit vals: [0.111  0.1075 0.1145 0.667 ]\n",
      "\n",
      " % diff vals: [ 4.8431e-06  3.4250e-05 -3.4405e-04  5.2736e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.004854\n",
      "         Iterations: 28\n",
      "         Function evaluations: 133\n",
      "         Gradient evaluations: 121\n",
      "False 1143.76346151526 1835.5694156033235 0.00485390286517368\n",
      " scan vals:  [0.111  0.1075 0.118  0.6635]\n",
      " fit vals: [0.111  0.1075 0.118  0.6635]\n",
      "\n",
      " % diff vals: [ 1.9146e-05  5.9269e-05 -5.2363e-04  8.0317e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001462\n",
      "         Iterations: 29\n",
      "         Function evaluations: 45\n",
      "         Gradient evaluations: 45\n",
      "True 1143.76346151526 2332.712413107897 0.0014617907929583265\n",
      " scan vals:  [0.111 0.111 0.104 0.674]\n",
      " fit vals: [0.111 0.111 0.104 0.674]\n",
      "\n",
      " % diff vals: [-4.9099e-05 -7.4264e-05  2.4755e-04 -1.7881e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000815\n",
      "         Iterations: 29\n",
      "         Function evaluations: 101\n",
      "         Gradient evaluations: 98\n",
      "True 1143.76346151526 2379.871556823886 0.0008154048372969539\n",
      " scan vals:  [0.111  0.111  0.1075 0.6705]\n",
      " fit vals: [0.111  0.111  0.1075 0.6705]\n",
      "\n",
      " % diff vals: [-3.6019e-05 -5.3757e-05  5.2489e-05  6.4466e-06]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001246\n",
      "         Iterations: 31\n",
      "         Function evaluations: 108\n",
      "         Gradient evaluations: 107\n",
      "True 1143.76346151526 2449.6286311810068 0.0012460043891454645\n",
      " scan vals:  [0.111 0.111 0.111 0.667]\n",
      " fit vals: [0.111 0.111 0.111 0.667]\n",
      "\n",
      " % diff vals: [-2.2468e-05 -3.2551e-05 -1.3642e-04  3.1857e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.002754\n",
      "         Iterations: 29\n",
      "         Function evaluations: 139\n",
      "         Gradient evaluations: 127\n",
      "False 1143.76346151526 2541.62234147811 0.0027535831351300213\n",
      " scan vals:  [0.111  0.111  0.1145 0.6635]\n",
      " fit vals: [0.111  0.111  0.1145 0.6635]\n",
      "\n",
      " % diff vals: [-8.7331e-06 -1.0295e-05 -3.2035e-04  5.8465e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.005338\n",
      "         Iterations: 29\n",
      "         Function evaluations: 107\n",
      "         Gradient evaluations: 96\n",
      "False 1143.76346151526 2655.521304369534 0.0053381422991909035\n",
      " scan vals:  [0.111 0.111 0.118 0.66 ]\n",
      " fit vals: [0.111 0.111 0.118 0.66 ]\n",
      "\n",
      " % diff vals: [ 5.6196e-06  1.2088e-05 -5.0191e-04  8.6756e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002916\n",
      "         Iterations: 31\n",
      "         Function evaluations: 50\n",
      "         Gradient evaluations: 50\n",
      "True 1143.76346151526 3717.133714616838 0.0029158072426080962\n",
      " scan vals:  [0.111  0.1145 0.104  0.6705]\n",
      " fit vals: [0.111  0.1145 0.104  0.6705]\n",
      "\n",
      " % diff vals: [-6.0665e-05 -1.1689e-04  2.6329e-04 -1.0835e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002296\n",
      "         Iterations: 31\n",
      "         Function evaluations: 45\n",
      "         Gradient evaluations: 45\n",
      "True 1143.76346151526 3791.8507704156605 0.0022962323577167035\n",
      " scan vals:  [0.111  0.1145 0.1075 0.667 ]\n",
      " fit vals: [0.111  0.1145 0.1075 0.667 ]\n",
      "\n",
      " % diff vals: [-4.7881e-05 -9.6928e-05  7.1064e-05  1.3153e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002754\n",
      "         Iterations: 32\n",
      "         Function evaluations: 49\n",
      "         Gradient evaluations: 49\n",
      "True 1143.76346151526 3889.2564148348793 0.002753645172180148\n",
      " scan vals:  [0.111  0.1145 0.111  0.6635]\n",
      " fit vals: [0.111  0.1145 0.111  0.6635]\n",
      "\n",
      " % diff vals: [-3.4592e-05 -7.6260e-05 -1.1510e-04  3.8202e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.004288\n",
      "         Iterations: 30\n",
      "         Function evaluations: 107\n",
      "         Gradient evaluations: 96\n",
      "False 1143.76346151526 4008.994216409995 0.0042880386141950656\n",
      " scan vals:  [0.111  0.1145 0.1145 0.66  ]\n",
      " fit vals: [0.111  0.1145 0.1145 0.66  ]\n",
      "\n",
      " % diff vals: [-2.3617e-05 -5.9447e-05 -2.9285e-04  6.5088e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.006899\n",
      "         Iterations: 32\n",
      "         Function evaluations: 210\n",
      "         Gradient evaluations: 196\n",
      "False 1143.76346151526 4150.736574047295 0.006899411571287976\n",
      " scan vals:  [0.111  0.1145 0.118  0.6565]\n",
      " fit vals: [0.111  0.1145 0.118  0.6565]\n",
      "\n",
      " % diff vals: [-6.5762e-06 -3.2870e-05 -4.7123e-04  9.1543e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.005447\n",
      "         Iterations: 32\n",
      "         Function evaluations: 113\n",
      "         Gradient evaluations: 103\n",
      "False 1143.76346151526 5757.056344971637 0.0054468541720635345\n",
      " scan vals:  [0.111 0.118 0.104 0.667]\n",
      " fit vals: [0.111 0.118 0.104 0.667]\n",
      "\n",
      " % diff vals: [-7.1945e-05 -1.5728e-04  2.7928e-04 -3.7499e-06]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.004854\n",
      "         Iterations: 33\n",
      "         Function evaluations: 68\n",
      "         Gradient evaluations: 67\n",
      "True 1143.76346151526 5857.361311637996 0.004854091934023005\n",
      " scan vals:  [0.111  0.118  0.1075 0.6635]\n",
      " fit vals: [0.111  0.118  0.1075 0.6635]\n",
      "\n",
      " % diff vals: [-5.9343e-05 -1.3777e-04  8.9976e-05  1.9851e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.005338\n",
      "         Iterations: 32\n",
      "         Function evaluations: 159\n",
      "         Gradient evaluations: 145\n",
      "False 1143.76346151526 5980.479065949298 0.005338316179703063\n",
      " scan vals:  [0.111 0.118 0.111 0.66 ]\n",
      " fit vals: [0.111 0.118 0.111 0.66 ]\n",
      "\n",
      " % diff vals: [-4.6471e-05 -1.1823e-04 -9.3945e-05  4.4751e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.006900\n",
      "         Iterations: 32\n",
      "         Function evaluations: 198\n",
      "         Gradient evaluations: 185\n",
      "False 1143.76346151526 6126.056270109958 0.006899524510136939\n",
      " scan vals:  [0.111  0.118  0.1145 0.6565]\n",
      " fit vals: [0.111  0.118  0.1145 0.6565]\n",
      "\n",
      " % diff vals: [-3.2903e-05 -9.6794e-05 -2.7121e-04  7.0261e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.009538\n",
      "         Iterations: 31\n",
      "         Function evaluations: 62\n",
      "         Gradient evaluations: 53\n",
      "False 1143.76346151526 6293.767488383017 0.009537714033116186\n",
      " scan vals:  [0.111 0.118 0.118 0.653]\n",
      " fit vals: [0.111 0.118 0.118 0.653]\n",
      "\n",
      " % diff vals: [-1.8731e-05 -7.5373e-05 -4.4476e-04  9.7172e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.003185\n",
      "         Iterations: 30\n",
      "         Function evaluations: 162\n",
      "         Gradient evaluations: 151\n",
      "False 1143.76346151526 2708.827814655278 0.003185273912431562\n",
      " scan vals:  [0.1145 0.104  0.104  0.6775]\n",
      " fit vals: [0.1145 0.104  0.104  0.6775]\n",
      "\n",
      " % diff vals: [-5.2522e-05  4.1875e-06  2.2727e-04 -2.6654e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002512\n",
      "         Iterations: 26\n",
      "         Function evaluations: 38\n",
      "         Gradient evaluations: 38\n",
      "True 1143.76346151526 2712.424425389603 0.002512075579744594\n",
      " scan vals:  [0.1145 0.104  0.1075 0.674 ]\n",
      " fit vals: [0.1145 0.104  0.1075 0.674 ]\n",
      "\n",
      " % diff vals: [-3.9388e-05  2.5416e-05  2.7992e-05 -1.6951e-06]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.002916\n",
      "         Iterations: 26\n",
      "         Function evaluations: 233\n",
      "         Gradient evaluations: 218\n",
      "False 1143.76346151526 2738.686589915738 0.0029158576329695236\n",
      " scan vals:  [0.1145 0.104  0.111  0.6705]\n",
      " fit vals: [0.1145 0.104  0.111  0.6705]\n",
      "\n",
      " % diff vals: [-2.5588e-05  4.7533e-05 -1.6489e-04  2.4295e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.004397\n",
      "         Iterations: 28\n",
      "         Function evaluations: 39\n",
      "         Gradient evaluations: 39\n",
      "True 1143.76346151526 2787.2376140734605 0.004396622048472601\n",
      " scan vals:  [0.1145 0.104  0.1145 0.667 ]\n",
      " fit vals: [0.1145 0.104  0.1145 0.667 ]\n",
      "\n",
      " % diff vals: [-1.1517e-05  7.0190e-05 -3.5162e-04  5.1393e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.006954\n",
      "         Iterations: 31\n",
      "         Function evaluations: 75\n",
      "         Gradient evaluations: 74\n",
      "True 1143.76346151526 2857.732906406122 0.0069543614382692924\n",
      " scan vals:  [0.1145 0.104  0.118  0.6635]\n",
      " fit vals: [0.1145 0.104  0.118  0.6635]\n",
      "\n",
      " % diff vals: [ 3.1460e-06  9.3641e-05 -5.3291e-04  7.9553e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.002512\n",
      "         Iterations: 31\n",
      "         Function evaluations: 270\n",
      "         Gradient evaluations: 254\n",
      "False 1143.76346151526 2720.3770657437294 0.0025120297531925307\n",
      " scan vals:  [0.1145 0.1075 0.104  0.674 ]\n",
      " fit vals: [0.1145 0.1075 0.104  0.674 ]\n",
      "\n",
      " % diff vals: [-6.3946e-05 -4.2557e-05  2.4111e-04 -1.9553e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.001866\n",
      "         Iterations: 28\n",
      "         Function evaluations: 103\n",
      "         Gradient evaluations: 92\n",
      "False 1143.76346151526 2756.465804046972 0.001865641979853332\n",
      " scan vals:  [0.1145 0.1075 0.1075 0.6705]\n",
      " fit vals: [0.1145 0.1075 0.1075 0.6705]\n",
      "\n",
      " % diff vals: [-5.3673e-05 -2.1942e-05  4.8726e-05  4.8706e-06]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002296\n",
      "         Iterations: 29\n",
      "         Function evaluations: 47\n",
      "         Gradient evaluations: 47\n",
      "True 1143.76346151526 2815.2237125591173 0.002296238555063995\n",
      " scan vals:  [0.1145 0.1075 0.111  0.667 ]\n",
      " fit vals: [0.1145 0.1075 0.111  0.667 ]\n",
      "\n",
      " % diff vals: [-3.7656e-05 -3.6050e-07 -1.4472e-04  3.0606e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.003804\n",
      "         Iterations: 31\n",
      "         Function evaluations: 46\n",
      "         Gradient evaluations: 46\n",
      "True 1143.76346151526 2896.2833140356197 0.003803814553615513\n",
      " scan vals:  [0.1145 0.1075 0.1145 0.6635]\n",
      " fit vals: [0.1145 0.1075 0.1145 0.6635]\n",
      "\n",
      " % diff vals: [-2.3751e-05  2.1858e-05 -3.2881e-04  5.7299e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.006388\n",
      "         Iterations: 29\n",
      "         Function evaluations: 107\n",
      "         Gradient evaluations: 97\n",
      "False 1143.76346151526 2999.3077951350006 0.006388370932033736\n",
      " scan vals:  [0.1145 0.1075 0.118  0.66  ]\n",
      " fit vals: [0.1145 0.1075 0.118  0.66  ]\n",
      "\n",
      " % diff vals: [-9.0559e-06  4.5304e-05 -5.0754e-04  8.4932e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.002916\n",
      "         Iterations: 30\n",
      "         Function evaluations: 91\n",
      "         Gradient evaluations: 81\n",
      "False 1143.76346151526 3449.2916113626206 0.0029158175719047183\n",
      " scan vals:  [0.1145 0.111  0.104  0.6705]\n",
      " fit vals: [0.1145 0.111  0.104  0.6705]\n",
      "\n",
      " % diff vals: [-7.5786e-05 -8.7560e-05  2.5597e-04 -1.2266e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.002296\n",
      "         Iterations: 33\n",
      "         Function evaluations: 158\n",
      "         Gradient evaluations: 145\n",
      "False 1143.76346151526 3515.4167687844642 0.002296241528111602\n",
      " scan vals:  [0.1145 0.111  0.1075 0.667 ]\n",
      " fit vals: [0.1145 0.111  0.1075 0.667 ]\n",
      "\n",
      " % diff vals: [-6.2444e-05 -6.6676e-05  6.2928e-05  1.1673e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.002754\n",
      "         Iterations: 33\n",
      "         Function evaluations: 50\n",
      "         Gradient evaluations: 50\n",
      "True 1143.76346151526 3604.2609663293883 0.0027536507496089104\n",
      " scan vals:  [0.1145 0.111  0.111  0.6635]\n",
      " fit vals: [0.1145 0.111  0.111  0.6635]\n",
      "\n",
      " % diff vals: [-4.9232e-05 -4.5631e-05 -1.2415e-04  3.6899e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.004288\n",
      "         Iterations: 32\n",
      "         Function evaluations: 191\n",
      "         Gradient evaluations: 175\n",
      "False 1143.76346151526 3715.4636552238358 0.004288040746228639\n",
      " scan vals:  [0.1145 0.111  0.1145 0.66  ]\n",
      " fit vals: [0.1145 0.111  0.1145 0.66  ]\n",
      "\n",
      " % diff vals: [-3.5472e-05 -2.4827e-05 -3.0470e-04  6.3189e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.006899\n",
      "         Iterations: 35\n",
      "         Function evaluations: 112\n",
      "         Gradient evaluations: 111\n",
      "True 1143.76346151526 3848.6936951915313 0.006899411751089097\n",
      " scan vals:  [0.1145 0.111  0.118  0.6565]\n",
      " fit vals: [0.1145 0.111  0.118  0.6565]\n",
      "\n",
      " % diff vals: [-2.1425e-05 -1.5498e-06 -4.8168e-04  9.0575e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.004397\n",
      "         Iterations: 33\n",
      "         Function evaluations: 131\n",
      "         Gradient evaluations: 118\n",
      "False 1143.76346151526 4862.646795237319 0.004396637123699918\n",
      " scan vals:  [0.1145 0.1145 0.104  0.667 ]\n",
      " fit vals: [0.1145 0.1145 0.104  0.667 ]\n",
      "\n",
      " % diff vals: [-8.6436e-05 -1.2854e-04  2.7114e-04 -5.3747e-06]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.003804\n",
      "         Iterations: 32\n",
      "         Function evaluations: 118\n",
      "         Gradient evaluations: 106\n",
      "False 1143.76346151526 4956.616710726739 0.003803871947708021\n",
      " scan vals:  [0.1145 0.1145 0.1075 0.6635]\n",
      " fit vals: [0.1145 0.1145 0.1075 0.6635]\n",
      "\n",
      " % diff vals: [-7.3394e-05 -1.0883e-04  8.1182e-05  1.8293e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.004288\n",
      "         Iterations: 32\n",
      "         Function evaluations: 45\n",
      "         Gradient evaluations: 45\n",
      "True 1143.76346151526 5073.394933315487 0.004288094686190791\n",
      " scan vals:  [0.1145 0.1145 0.111  0.66  ]\n",
      " fit vals: [0.1145 0.1145 0.111  0.66  ]\n",
      "\n",
      " % diff vals: [-6.0395e-05 -8.8429e-05 -1.0327e-04  4.3185e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.005849\n",
      "         Iterations: 31\n",
      "         Function evaluations: 44\n",
      "         Gradient evaluations: 44\n",
      "True 1143.76346151526 5212.625833940591 0.0058492989084641695\n",
      " scan vals:  [0.1145 0.1145 0.1145 0.6565]\n",
      " fit vals: [0.1145 0.1145 0.1145 0.6565]\n",
      "\n",
      " % diff vals: [-4.7025e-05 -6.7360e-05 -2.8208e-04  6.9146e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.008487\n",
      "         Iterations: 32\n",
      "         Function evaluations: 103\n",
      "         Gradient evaluations: 93\n",
      "False 1143.76346151526 5373.982103611656 0.00848748357720138\n",
      " scan vals:  [0.1145 0.1145 0.118  0.653 ]\n",
      " fit vals: [0.1145 0.1145 0.118  0.653 ]\n",
      "\n",
      " % diff vals: [-3.3367e-05 -4.5991e-05 -4.5649e-04  9.6403e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.006954\n",
      "         Iterations: 32\n",
      "         Function evaluations: 45\n",
      "         Gradient evaluations: 45\n",
      "True 1143.76346151526 6931.990259091606 0.006954486851095064\n",
      " scan vals:  [0.1145 0.118  0.104  0.6635]\n",
      " fit vals: [0.1145 0.118  0.104  0.6635]\n",
      "\n",
      " % diff vals: [-9.6093e-05 -1.6822e-04  2.8751e-04  1.4334e-06]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.006389\n",
      "         Iterations: 30\n",
      "         Function evaluations: 95\n",
      "         Gradient evaluations: 85\n",
      "False 1143.76346151526 7051.831767113281 0.006388533980734357\n",
      " scan vals:  [0.1145 0.118  0.1075 0.66  ]\n",
      " fit vals: [0.1145 0.118  0.1075 0.66  ]\n",
      "\n",
      " % diff vals: [-8.4024e-05 -1.4737e-04  9.7422e-05  2.5055e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.006900\n",
      "         Iterations: 33\n",
      "         Function evaluations: 255\n",
      "         Gradient evaluations: 241\n",
      "False 1143.76346151526 7194.604479088294 0.006899567731977048\n",
      " scan vals:  [0.1145 0.118  0.111  0.6565]\n",
      " fit vals: [0.1145 0.118  0.111  0.6565]\n",
      "\n",
      " % diff vals: [-7.1229e-05 -1.3006e-04 -8.2276e-05  4.9709e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.008488\n",
      "         Iterations: 33\n",
      "         Function evaluations: 44\n",
      "         Gradient evaluations: 44\n",
      "True 1143.76346151526 7359.95591860272 0.008487587410434243\n",
      " scan vals:  [0.1145 0.118  0.1145 0.653 ]\n",
      " fit vals: [0.1145 0.118  0.1145 0.653 ]\n",
      "\n",
      " % diff vals: [-5.8097e-05 -1.0844e-04 -2.5833e-04  7.5077e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.011153\n",
      "         Iterations: 33\n",
      "         Function evaluations: 44\n",
      "         Gradient evaluations: 44\n",
      "True 1143.76346151526 7547.560993509089 0.011152588079758871\n",
      " scan vals:  [0.1145 0.118  0.118  0.6495]\n",
      " fit vals: [0.1145 0.118  0.118  0.6495]\n",
      "\n",
      " % diff vals: [-4.4487e-05 -8.7162e-05 -4.2960e-04  1.0172e-04]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.005663\n",
      "         Iterations: 33\n",
      "         Function evaluations: 114\n",
      "         Gradient evaluations: 105\n",
      "False 1143.76346151526 4232.251882508999 0.00566273208043375\n",
      " scan vals:  [0.118 0.104 0.104 0.674]\n",
      " fit vals: [0.118 0.104 0.104 0.674]\n",
      "\n",
      " % diff vals: [-8.0691e-05 -1.1390e-05  2.3737e-04 -2.0742e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.005016\n",
      "         Iterations: 33\n",
      "         Function evaluations: 113\n",
      "         Gradient evaluations: 98\n",
      "False 1143.76346151526 4252.901463025435 0.005016341329875012\n",
      " scan vals:  [0.118  0.104  0.1075 0.6705]\n",
      " fit vals: [0.118  0.104  0.1075 0.6705]\n",
      "\n",
      " % diff vals: [-6.7167e-05  1.0733e-05  3.9311e-05  3.8531e-06]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.005447\n",
      "         Iterations: 34\n",
      "         Function evaluations: 50\n",
      "         Gradient evaluations: 50\n",
      "True 1143.76346151526 4296.355153897743 0.005446936274726895\n",
      " scan vals:  [0.118 0.104 0.111 0.667]\n",
      " fit vals: [0.118 0.104 0.111 0.667]\n",
      "\n",
      " % diff vals: [-5.4190e-05  3.2384e-05 -1.5152e-04  2.9752e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.006955\n",
      "         Iterations: 33\n",
      "         Function evaluations: 112\n",
      "         Gradient evaluations: 101\n",
      "False 1143.76346151526 4362.236004390347 0.006954510934548505\n",
      " scan vals:  [0.118  0.104  0.1145 0.6635]\n",
      " fit vals: [0.118  0.104  0.1145 0.6635]\n",
      "\n",
      " % diff vals: [-4.0418e-05  5.4858e-05 -3.3660e-04  5.6675e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.009539\n",
      "         Iterations: 34\n",
      "         Function evaluations: 136\n",
      "         Gradient evaluations: 123\n",
      "False 1143.76346151526 4450.198768549335 0.009539063249509514\n",
      " scan vals:  [0.118 0.104 0.118 0.66 ]\n",
      " fit vals: [0.118 0.104 0.118 0.66 ]\n",
      "\n",
      " % diff vals: [-2.6042e-05  7.8072e-05 -5.1598e-04  8.4603e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.005016\n",
      "         Iterations: 32\n",
      "         Function evaluations: 155\n",
      "         Gradient evaluations: 142\n",
      "False 1143.76346151526 4271.749058451072 0.005016290519709716\n",
      " scan vals:  [0.118  0.1075 0.104  0.6705]\n",
      " fit vals: [0.118  0.1075 0.104  0.6705]\n",
      "\n",
      " % diff vals: [-9.0864e-05 -5.6297e-05  2.5049e-04 -1.3836e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.004397\n",
      "         Iterations: 30\n",
      "         Function evaluations: 47\n",
      "         Gradient evaluations: 47\n",
      "True 1143.76346151526 4325.180936367814 0.004396712632412498\n",
      " scan vals:  [0.118  0.1075 0.1075 0.667 ]\n",
      " fit vals: [0.118  0.1075 0.1075 0.667 ]\n",
      "\n",
      " % diff vals: [-7.8188e-05 -3.5680e-05  5.6137e-05  1.0535e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.004854\n",
      "         Iterations: 32\n",
      "         Function evaluations: 108\n",
      "         Gradient evaluations: 96\n",
      "False 1143.76346151526 4401.418954111677 0.004854118649090193\n",
      " scan vals:  [0.118  0.1075 0.111  0.6635]\n",
      " fit vals: [0.118  0.1075 0.111  0.6635]\n",
      "\n",
      " % diff vals: [-6.5050e-05 -1.4373e-05 -1.3186e-04  3.5957e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.006389\n",
      "         Iterations: 31\n",
      "         Function evaluations: 105\n",
      "         Gradient evaluations: 93\n",
      "False 1143.76346151526 4500.0954336567565 0.00638850678563444\n",
      " scan vals:  [0.118  0.1075 0.1145 0.66  ]\n",
      " fit vals: [0.118  0.1075 0.1145 0.66  ]\n",
      "\n",
      " % diff vals: [-5.1809e-05  7.5217e-06 -3.1425e-04  6.2554e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.009000\n",
      "         Iterations: 29\n",
      "         Function evaluations: 177\n",
      "         Gradient evaluations: 165\n",
      "False 1143.76346151526 4620.872955499106 0.008999873641898526\n",
      " scan vals:  [0.118  0.1075 0.118  0.6565]\n",
      " fit vals: [0.118  0.1075 0.118  0.6565]\n",
      "\n",
      " % diff vals: [-3.8211e-05  2.9541e-05 -4.9154e-04  9.0379e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.005447\n",
      "         Iterations: 29\n",
      "         Function evaluations: 97\n",
      "         Gradient evaluations: 85\n",
      "False 1143.76346151526 5029.434579542502 0.005446880830678945\n",
      " scan vals:  [0.118 0.111 0.104 0.667]\n",
      " fit vals: [0.118 0.111 0.104 0.667]\n",
      "\n",
      " % diff vals: [-1.0105e-04 -9.9982e-05  2.6547e-04 -6.8763e-06]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.004854\n",
      "         Iterations: 32\n",
      "         Function evaluations: 150\n",
      "         Gradient evaluations: 137\n",
      "False 1143.76346151526 5113.189124316793 0.004854114357365684\n",
      " scan vals:  [0.118  0.111  0.1075 0.6635]\n",
      " fit vals: [0.118  0.111  0.1075 0.6635]\n",
      "\n",
      " % diff vals: [-8.8624e-05 -7.9456e-05  7.3760e-05  1.7102e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.005338\n",
      "         Iterations: 32\n",
      "         Function evaluations: 45\n",
      "         Gradient evaluations: 45\n",
      "True 1143.76346151526 5219.798182135133 0.005338334065834469\n",
      " scan vals:  [0.118 0.111 0.111 0.66 ]\n",
      " fit vals: [0.118 0.111 0.111 0.66 ]\n",
      "\n",
      " % diff vals: [-7.5765e-05 -5.8737e-05 -1.1166e-04  4.2203e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.006900\n",
      "         Iterations: 31\n",
      "         Function evaluations: 44\n",
      "         Gradient evaluations: 44\n",
      "True 1143.76346151526 5348.901062657229 0.006899535346896999\n",
      " scan vals:  [0.118  0.111  0.1145 0.6565]\n",
      " fit vals: [0.118  0.111  0.1145 0.6565]\n",
      "\n",
      " % diff vals: [-6.2472e-05 -3.7306e-05 -2.9135e-04  6.8350e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.009538\n",
      "         Iterations: 32\n",
      "         Function evaluations: 145\n",
      "         Gradient evaluations: 134\n",
      "False 1143.76346151526 5500.166071126257 0.009537717694261509\n",
      " scan vals:  [0.118 0.111 0.118 0.653]\n",
      " fit vals: [0.118 0.111 0.118 0.653]\n",
      "\n",
      " % diff vals: [-4.8606e-05 -1.5056e-05 -4.6558e-04  9.5473e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.006955\n",
      "         Iterations: 36\n",
      "         Function evaluations: 118\n",
      "         Gradient evaluations: 116\n",
      "True 1143.76346151526 6472.191087624339 0.0069545021454114125\n",
      " scan vals:  [0.118  0.1145 0.104  0.6635]\n",
      " fit vals: [0.118  0.1145 0.104  0.6635]\n",
      "\n",
      " % diff vals: [-1.1072e-04 -1.4053e-04  2.8027e-04  1.1249e-08]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.006389\n",
      "         Iterations: 32\n",
      "         Function evaluations: 98\n",
      "         Gradient evaluations: 87\n",
      "False 1143.76346151526 6584.073047392839 0.006388548106089299\n",
      " scan vals:  [0.118  0.1145 0.1075 0.66  ]\n",
      " fit vals: [0.118  0.1145 0.1075 0.66  ]\n",
      "\n",
      " % diff vals: [-9.7991e-05 -1.2429e-04  9.8600e-05  2.3022e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.006900\n",
      "         Iterations: 36\n",
      "         Function evaluations: 204\n",
      "         Gradient evaluations: 190\n",
      "False 1143.76346151526 6718.897396520181 0.0068995786998603025\n",
      " scan vals:  [0.118  0.1145 0.111  0.6565]\n",
      " fit vals: [0.118  0.1145 0.111  0.6565]\n",
      "\n",
      " % diff vals: [-8.6073e-05 -1.0057e-04 -9.1384e-05  4.8461e-05]\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.008488\n",
      "         Iterations: 35\n",
      "         Function evaluations: 51\n",
      "         Gradient evaluations: 51\n",
      "True 1143.76346151526 6876.30842583459 0.008487595337826347\n",
      " scan vals:  [0.118  0.1145 0.1145 0.653 ]\n",
      " fit vals: [0.118  0.1145 0.1145 0.653 ]\n",
      "\n",
      " % diff vals: [-7.2998e-05 -7.9754e-05 -2.6828e-04  7.4216e-05]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.011153\n",
      "         Iterations: 34\n",
      "         Function evaluations: 130\n",
      "         Gradient evaluations: 117\n",
      "False 1143.76346151526 7055.978325752974 0.011152591329686387\n",
      " scan vals:  [0.118  0.1145 0.118  0.6495]\n",
      " fit vals: [0.118  0.1145 0.118  0.6495]\n",
      "\n",
      " % diff vals: [-6.0007e-05 -5.8001e-05 -4.3990e-04  1.0105e-04]\n",
      "\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: 0.009539\n",
      "         Iterations: 35\n",
      "         Function evaluations: 184\n",
      "         Gradient evaluations: 168\n",
      "False 1143.76346151526 8571.399037832944 0.009539155065872107\n",
      " scan vals:  [0.118 0.118 0.104 0.66 ]\n",
      " fit vals: [0.118 0.118 0.104 0.66 ]\n",
      "\n",
      " % diff vals: [-1.2018e-04 -1.7963e-04  2.9599e-04  6.9599e-06]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# carry out the scan #\n",
    "\n",
    "# minimizer options\n",
    "min_options = dict(\n",
    "                   #eps=1e-10,\n",
    "                   gtol=1e-3, \n",
    "                   disp=True\n",
    "                  )\n",
    "\n",
    "results = []\n",
    "cost = []\n",
    "sv_accept = []\n",
    "mask = fit_data._pmask\n",
    "pinit = params_pre[mask]\n",
    "for sv in tqdm(scan_vals):\n",
    "    \n",
    "    # randomize n.p.\n",
    "    mask[:4] = False\n",
    "    np_random = params_pre[mask] + fit_data._perr_init[mask]*np.random.randn(mask.sum())\n",
    "    fit_data._pval_init[mask] = np_random\n",
    "    #sv[mask] = np_random\n",
    "    mask[:4] = True\n",
    "    \n",
    "    # generate data from scan values w/ statistical variation\n",
    "    sample = dict()\n",
    "    for category in fit_data._categories:\n",
    "        val, var = fit_data.mixture_model(sv, category)\n",
    "        sample[category] = [np.random.poisson(val), val]\n",
    "        #sample[category] = [val, val]\n",
    "    \n",
    "    fobj.keywords['data'] = sample\n",
    "    fobj_jac.keywords['data'] = sample\n",
    "\n",
    "    # carry out minimization\n",
    "    result = minimize(fobj, pinit,\n",
    "                      method  = 'BFGS', \n",
    "                      options = min_options,\n",
    "                      jac     = fobj_jac,\n",
    "                      #args    = (sample)\n",
    "                     )\n",
    "    print(result.success, fit_data.objective(pinit), fit_data.objective(sv[mask]), result.fun)\n",
    "    #print(' jacobian: ', result.jac)\n",
    "    #print(' init vals: ', pinit)\n",
    "    #print(' nps: ', np_random)\n",
    "    print(' scan vals: ', sv[:4])\n",
    "    print(' fit vals:', result.x[:4], end='\\n\\n')\n",
    "    print(' % diff vals:', 100*(result.x[:4] - sv[:4])/sv[:4], end='\\n\\n')\n",
    "\n",
    "    results.append(result.x)\n",
    "    cost.append(result.fun)\n",
    "    sv_accept.append(sv[mask])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T23:12:09.134455Z",
     "start_time": "2020-04-29T23:12:09.130286Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#calculate biases\n",
    "results = np.array(results)\n",
    "sv_accept = np.array(sv_accept)\n",
    "cost = np.array(cost)\n",
    "\n",
    "diff = (results - sv_accept)\n",
    "diff[:,:4] /= 0.01*pinit[:4]\n",
    "#diff[:,:4] /= 0.01*sv_accept[:,:4]\n",
    "diff[:,4:diff.shape[1]] /= params['err_init'][4:diff.shape[1]].values\n",
    "\n",
    "#diff = np.array([d for d in diff if np.all((d > -10) & (d < 10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T23:12:09.370262Z",
     "start_time": "2020-04-29T23:12:09.136677Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# plot the cost\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10), facecolor='white')\n",
    "\n",
    "cost = cost[cost<600]\n",
    "cost_mean, cost_err = cost.mean(), cost.std()\n",
    "ax.hist(cost, bins=np.linspace(np.max([0, cost_mean - 5*cost_err]), cost_mean + 5*cost_err, 25), histtype='stepfilled')\n",
    "ax.set_xlabel(r'$NLL_{fit}$')\n",
    "ax.set_ylabel('Entries')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T23:12:09.963165Z",
     "start_time": "2020-04-29T23:12:09.371558Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# branching fraction scans\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10), facecolor='white', sharex=False, sharey=False)\n",
    "\n",
    "beta_val = sv_accept[:,:4]\n",
    "beta_obs = results[:,:4]\n",
    "\n",
    "ax = axes[0][0]\n",
    "ax.plot(beta_val[:,0], beta_obs[:,0], 'C0o', alpha=0.1)\n",
    "ax.plot([0.1, 0.12], [0.1, 0.12], 'r:')\n",
    "ax.set_xlim(0.102, 0.12)\n",
    "ax.set_ylim(0.102, 0.12)\n",
    "ax.set_ylabel(r'$B_{obs.}$')\n",
    "ax.set_title(r'$W\\rightarrow e$', size=20)\n",
    "\n",
    "ax = axes[0][1]\n",
    "ax.plot(beta_val[:,1], beta_obs[:,1], 'C0o', alpha=0.1)\n",
    "ax.plot([0.1, 0.12], [0.1, 0.12], 'r:')\n",
    "ax.set_xlim(0.102, 0.12)\n",
    "ax.set_ylim(0.102, 0.12)\n",
    "ax.set_title(r'$W\\rightarrow\\mu$', size=20)\n",
    "\n",
    "ax = axes[1][0]\n",
    "ax.plot(beta_val[:,2], beta_obs[:,2], 'C0o', alpha=0.1)\n",
    "ax.plot([0.1, 0.12], [0.1, 0.12], 'r:')\n",
    "ax.set_xlim(0.102, 0.12)\n",
    "ax.set_ylim(0.102, 0.12)\n",
    "ax.set_ylabel(r'$B_{obs.}$')\n",
    "ax.set_xlabel(r'$B_{true}$')\n",
    "ax.set_title(r'$W\\rightarrow\\tau$', size=20)\n",
    "\n",
    "ax = axes[1][1]\n",
    "ax.plot(beta_val[:,3], beta_obs[:,3], 'C0o', alpha=0.1)\n",
    "ax.plot([0.64, 0.72], [0.64, 0.72], 'r:')\n",
    "ax.set_xlim(0.64, 0.695)\n",
    "ax.set_ylim(0.64, 0.695)\n",
    "ax.set_xlabel(r'$B_{true}$')\n",
    "ax.set_title(r'$W\\rightarrow h$', size=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/systematics/bias_tests/beta_scan.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T23:12:10.826182Z",
     "start_time": "2020-04-29T23:12:09.964491Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# branching fraction scans\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10), facecolor='white', sharex=True, sharey=False)\n",
    "bins = np.linspace(-10, 10, 80)\n",
    "\n",
    "ax = axes[0][0]\n",
    "dbeta = 100*(beta_obs[:,0] - beta_val[:,0])/beta_val[:,0]\n",
    "ax.hist(dbeta, bins[::2], alpha=0.9, density=True)\n",
    "ax.plot(bins, norm.pdf(bins, loc=dbeta.mean(), scale=dbeta.std()))\n",
    "ax.text(0.1, 0.9, r'$\\mu =$' + f'{dbeta.mean():.3f}', transform=ax.transAxes)\n",
    "ax.text(0.1, 0.8, r'$\\sigma =$' + f'{dbeta.std():.3f}', transform=ax.transAxes)\n",
    "ax.set_ylabel('trial')\n",
    "ax.set_title(r'$W\\rightarrow e$', size=20)\n",
    "\n",
    "ax = axes[0][1]\n",
    "dbeta = 100*(beta_obs[:,1] - beta_val[:,1])/beta_val[:,1]\n",
    "ax.hist(dbeta, bins[::2], alpha=0.9, density=True)\n",
    "ax.plot(bins, norm.pdf(bins, loc=dbeta.mean(), scale=dbeta.std()))\n",
    "ax.text(0.1, 0.9, r'$\\mu =$' + f'{dbeta.mean():.3f}', transform=ax.transAxes)\n",
    "ax.text(0.1, 0.8, r'$\\sigma =$' + f'{dbeta.std():.3f}', transform=ax.transAxes)\n",
    "ax.set_title(r'$W\\rightarrow\\mu$', size=20)\n",
    "\n",
    "ax = axes[1][0]\n",
    "dbeta = 100*(beta_obs[:,2] - beta_val[:,2])/beta_val[:,2]\n",
    "ax.hist(dbeta, bins[::2], alpha=0.9, density=True)\n",
    "ax.plot(bins, norm.pdf(bins, loc=dbeta.mean(), scale=dbeta.std()))\n",
    "ax.text(0.1, 0.9, r'$\\mu =$' + f'{dbeta.mean():.3f}', transform=ax.transAxes)\n",
    "ax.text(0.1, 0.8, r'$\\sigma =$' + f'{dbeta.std():.3f}', transform=ax.transAxes)\n",
    "ax.set_ylabel('trial')\n",
    "ax.set_xlabel(r'$\\frac{B_{obs} - B_{true}}{B_{true}}$ (%)')\n",
    "ax.set_title(r'$W\\rightarrow\\tau$', size=20)\n",
    "\n",
    "ax = axes[1][1]\n",
    "dbeta = 100*(beta_obs[:,3] - beta_val[:,3])/beta_val[:,3]\n",
    "ax.hist(dbeta, bins[::2], alpha=0.9, density=True)\n",
    "ax.plot(bins, norm.pdf(bins, loc=dbeta.mean(), scale=dbeta.std()))\n",
    "ax.text(0.1, 0.9, r'$\\mu =$' + f'{dbeta.mean():.3f}', transform=ax.transAxes)\n",
    "ax.text(0.1, 0.8, r'$\\sigma =$' + f'{dbeta.std():.3f}', transform=ax.transAxes)\n",
    "ax.set_xlabel(r'$\\frac{B_{obs} - B_{true}}{B_{true}}$ (%)')\n",
    "ax.set_title(r'$W\\rightarrow h$', size=20)\n",
    "\n",
    "ax.set_xlim(-10, 10)\n",
    "ax.set_ylim(0., None)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/systematics/bias_tests/beta_bias.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T23:12:11.077329Z",
     "start_time": "2020-04-29T23:12:10.827508Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#plotting the results (compare to asimov dataset)\n",
    "fig, axes = plt.subplots(2, 1, figsize=(30, 15), facecolor='white', sharex=True, gridspec_kw={'height_ratios':[3,1]})\n",
    "\n",
    "df_pulls = pd.read_csv('data/model_parameters_asimov.csv').query('active == True')\n",
    "df_pulls.loc[:3, 'ratio'] *= 100\n",
    "df_pulls = df_pulls.set_index('name')\n",
    "pull_post = (df_pulls['val_fit'] - df_pulls['val_init'])/df_pulls['err_init']\n",
    "\n",
    "nparams = params[mask].shape[0]\n",
    "xticks = np.outer(np.arange(nparams), np.ones(diff.shape[0])).T\n",
    "ax = axes[0]\n",
    "ax.plot(xticks+1,  diff, 'ko', alpha=0.1, markersize=4, )\n",
    "ax.errorbar(xticks[0]+1,  diff.mean(axis=0), diff.std(axis=0), fmt='C0o', capsize=10, elinewidth=5, label='scan')\n",
    "ax.errorbar(xticks[0]+1,  pull_post.values, df_pulls['ratio'], fmt='C1o', capsize=10, elinewidth=5, label='Hessian')\n",
    "ax.fill_between([-0.5, nparams+0.5], [-1, -1], [1, 1], color='C0', alpha=0.25)\n",
    "#ax.boxplot(diff)\n",
    "\n",
    "# extra dressing\n",
    "ax.set_ylabel(r'$\\delta\\theta_{post}/\\delta\\theta_{pre}$')\n",
    "ax.set_ylim(-2.5, 2.5)\n",
    "ax.grid(linestyle='--', axis='y')\n",
    "ax.legend(fontsize=20)\n",
    "\n",
    "ax = axes[1]\n",
    "err_ratio = diff.std(axis=0)/df_pulls['ratio'].values\n",
    "ax.plot(xticks[0]+1,  err_ratio, 'ko', alpha=0.9, markersize=10)\n",
    "\n",
    "ax.set_xticks(xticks[0]+1)\n",
    "ax.set_xticklabels(params[mask].label, size=24)\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)\n",
    "ax.set_xlim(4.5, nparams+0.5)\n",
    "\n",
    "ax.set_ylabel(r'toys/$\\mathcal{H}_{NLL}$')\n",
    "ax.set_ylim(0.25, 1.75)\n",
    "ax.grid(linestyle='--', axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/new_pulls.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T23:12:11.077985Z",
     "start_time": "2020-04-29T22:28:30.517Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#plotting the results\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10), facecolor='white')\n",
    "\n",
    "xticks = np.outer(np.arange(4), np.ones(diff.shape[0])).T\n",
    "ax.plot(xticks+1,  diff[:,:4], 'ko', alpha=0.1, markersize=4)\n",
    "#ax.boxplot(diff)\n",
    "ax.errorbar(xticks[0,:4]+1,  diff[:,:4].mean(axis=0), diff[:,:4].std(axis=0), fmt='C0o', capsize=10, elinewidth=5)\n",
    "ax.fill_between([-0.5, nparams+0.5], [-1, -1], [1, 1], color='C0', alpha=0.25)\n",
    "\n",
    "print(diff[:,:4].std(axis=0))\n",
    "\n",
    "# extra dressing\n",
    "ax.set_xticks(xticks[0,:4]+1)\n",
    "ax.set_xticklabels(params.label[:4], size=24)\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)\n",
    "\n",
    "ax.set_ylabel(r'$\\delta\\theta/\\theta$ (%)')\n",
    "ax.set_xlim(0.5, nparams+0.5)\n",
    "ax.set_xlim(0.5, 4.5)\n",
    "ax.set_ylim(-2.5, 2.5)\n",
    "ax.grid(linestyle='--', axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/systematics/bias_tests/beta.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T23:12:11.078680Z",
     "start_time": "2020-04-29T22:28:30.519Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#plotting the results\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10), facecolor='white')\n",
    "\n",
    "ip_low, ip_high = 4, 7 + fit_data._nnorm\n",
    "xticks = np.outer(np.arange(ip_high-ip_low), np.ones(diff.shape[0])).T\n",
    "diff_trim = diff[:, ip_low:ip_high]\n",
    "ax.plot(xticks+1,  diff_trim, 'ko', alpha=0.1, markersize=4, )\n",
    "ax.errorbar(xticks[0]+1,  diff_trim.mean(axis=0), diff_trim.std(axis=0), fmt='C0o', capsize=10, elinewidth=5)\n",
    "\n",
    "# extra dressing\n",
    "ax.fill_between([0.5, ip_high - ip_low + 0.5], [-1, -1], [1, 1], color='C0', alpha=0.25)\n",
    "\n",
    "ax.set_xticks(xticks[0]+1)\n",
    "ax.set_xticklabels(params.label[ip_low:ip_high], size=24)\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)\n",
    "\n",
    "ax.set_ylabel(r'$\\sigma_{toys}/\\sigma_{pre}$')\n",
    "ax.set_xlim(0.5, ip_high - ip_low + 0.5)\n",
    "ax.set_ylim(-2.5, 2.5)\n",
    "ax.grid(linestyle='--', axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/systematics/bias_tests/norm_params.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T23:12:11.079242Z",
     "start_time": "2020-04-29T22:28:30.521Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#plotting the results\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10), facecolor='white')\n",
    "\n",
    "ip_low, ip_high = 18, 46\n",
    "xticks = np.outer(np.arange(ip_high-ip_low), np.ones(diff.shape[0])).T\n",
    "diff_trim = diff[:, ip_low:ip_high]\n",
    "ax.plot(xticks+1,  diff_trim, 'ko', alpha=0.1, markersize=4, )\n",
    "ax.errorbar(xticks[0]+1,  diff_trim.mean(axis=0), diff_trim.std(axis=0), fmt='C0o', capsize=10, elinewidth=5)\n",
    "\n",
    "# extra dressing\n",
    "ax.fill_between([0.5, ip_high - ip_low + 0.5], [-1, -1], [1, 1], color='C0', alpha=0.25)\n",
    "\n",
    "ax.set_xticks(xticks[0]+1)\n",
    "ax.set_xticklabels(params.label[ip_low:ip_high], size=24)\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)\n",
    "\n",
    "ax.set_ylabel(r'$\\sigma_{toys}/\\sigma_{pre}$')\n",
    "ax.set_xlim(0.5, ip_high - ip_low + 0.5)\n",
    "ax.set_ylim(-2.5, 2.5)\n",
    "ax.grid(linestyle='--', axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/systematics/bias_tests/shape_reco_params.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T23:12:11.079800Z",
     "start_time": "2020-04-29T22:28:30.524Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#plotting the results\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10), facecolor='white')\n",
    "\n",
    "ip_low, ip_high = 47, 65\n",
    "xticks = np.outer(np.arange(ip_high-ip_low), np.ones(diff.shape[0])).T\n",
    "diff_trim = diff[:, ip_low:ip_high]\n",
    "ax.plot(xticks+1,  diff_trim, 'ko', alpha=0.1, markersize=4, )\n",
    "ax.errorbar(xticks[0]+1,  diff_trim.mean(axis=0), diff_trim.std(axis=0), fmt='C0o', capsize=10, elinewidth=5)\n",
    "\n",
    "# extra dressing\n",
    "ax.fill_between([0.5, ip_high - ip_low + 0.5], [-1, -1], [1, 1], color='C0', alpha=0.25)\n",
    "\n",
    "ax.set_xticks(xticks[0]+1)\n",
    "ax.set_xticklabels(params.label[ip_low:ip_high], size=24)\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)\n",
    "\n",
    "ax.set_ylabel(r'$\\sigma_{toys}/\\sigma_{pre}$')\n",
    "ax.set_xlim(0.5, ip_high - ip_low + 0.5)\n",
    "ax.set_ylim(-2.5, 2.5)\n",
    "ax.grid(linestyle='--', axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/systematics/bias_tests/shape_btag_params.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T23:12:11.080433Z",
     "start_time": "2020-04-29T22:28:30.526Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#plotting the results\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10), facecolor='white')\n",
    "\n",
    "ip_low, ip_high = 65, 84\n",
    "xticks = np.outer(np.arange(ip_high-ip_low), np.ones(diff.shape[0])).T\n",
    "diff_trim = diff[:, ip_low:ip_high]\n",
    "ax.plot(xticks+1,  diff_trim, 'ko', alpha=0.1, markersize=4, )\n",
    "ax.errorbar(xticks[0]+1,  diff_trim.mean(axis=0), diff_trim.std(axis=0), fmt='C0o', capsize=10, elinewidth=5)\n",
    "\n",
    "# extra dressing\n",
    "ax.fill_between([0.5, ip_high - ip_low + 0.5], [-1, -1], [1, 1], color='C0', alpha=0.25)\n",
    "\n",
    "ax.set_xticks(xticks[0]+1)\n",
    "ax.set_xticklabels(params.label[ip_low:ip_high], size=24)\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=90)\n",
    "\n",
    "ax.set_ylabel(r'$\\sigma_{toys}/\\sigma_{pre}$')\n",
    "ax.set_xlim(0.5, ip_high - ip_low + 0.5)\n",
    "ax.set_ylim(-2.5, 2.5)\n",
    "ax.grid(linestyle='--', axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/systematics/bias_tests/shape_jes_params.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "29px",
    "width": "251px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "49px",
    "left": "0px",
    "right": "1493.87px",
    "top": "90.9965px",
    "width": "242px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "677.85px",
    "left": "1071px",
    "right": "20px",
    "top": "170px",
    "width": "659px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "state": {
    "012f8bbe2fdb410dae6e2cde9d7fe5cb": {
     "views": []
    },
    "080556076f174648bddf64f17a54c523": {
     "views": []
    },
    "0ad83b5f67484ae5b8fd8dd43ccc39bd": {
     "views": []
    },
    "15acd81a9adc493683d9b63813f000bf": {
     "views": []
    },
    "1840cb6fded848b4ae95ec8d3db15ab2": {
     "views": []
    },
    "1dd83f822e074642ae4255b15ee661cf": {
     "views": []
    },
    "1e71a878e6474912a0efc497ecc5d65b": {
     "views": []
    },
    "2022ed83777b4963b630b5c46239e218": {
     "views": []
    },
    "21c4c57bfc48495194663e6a4fbac488": {
     "views": []
    },
    "22c45c75435348c0b9501d493d69fdca": {
     "views": []
    },
    "2635f668a1af4a9db2642e705d7c73ff": {
     "views": []
    },
    "2ad5ddd9347e451b9290e5b4179ab9a2": {
     "views": []
    },
    "2c062b5778024117984822b63b0593d7": {
     "views": []
    },
    "2f5eab2f6fb24192b76a5ffe99195d44": {
     "views": []
    },
    "31632517325046e8b0cb62e4f4ed2480": {
     "views": []
    },
    "3562b97192ed4d42bbab17f77c290f6b": {
     "views": []
    },
    "38a7cc053723492b921cf9f084ed243c": {
     "views": []
    },
    "3b5750b20e1745879ca0f965aad7b614": {
     "views": []
    },
    "3f1cbabbe2694a9dabe3f1c2e09d0ee2": {
     "views": []
    },
    "3fab6a26a70c4238a668a46d4dc88bf6": {
     "views": []
    },
    "3fb3c7a25e954a4888996976fa107737": {
     "views": []
    },
    "415db64fbc574daea8457ab600392f09": {
     "views": []
    },
    "4463de406b4645a4b562fe7917380ff9": {
     "views": []
    },
    "487e5450b5a24507932709f1fa8f59c1": {
     "views": []
    },
    "48aba73013e74e71927f71d42fb44d14": {
     "views": []
    },
    "4a19ad30f77e4fe6a2c84c8b62378a47": {
     "views": []
    },
    "4bc83ff5270d41679d76d26cdded8313": {
     "views": []
    },
    "4bdd9dd5c5c64646a27fa9096851458b": {
     "views": []
    },
    "5014cd42705f45178d5e6eeffd70f119": {
     "views": []
    },
    "5259b340b68e4fdb97fb4eaf9d98d954": {
     "views": []
    },
    "5986ef5b605a42aca10bc5834529ee06": {
     "views": []
    },
    "5c1aa44589a140eb9709734c843abde6": {
     "views": []
    },
    "600cd9ca4f4c46d4ad6fe57df107675a": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "61fe369ebdd14eaa89de110f6186e6b7": {
     "views": []
    },
    "62ac836017ae47a38f8fde806c5ec9b7": {
     "views": []
    },
    "632ccbfabe91405aa1c5a77c9ea754db": {
     "views": []
    },
    "66175f618ea5472baac618f998d2c06c": {
     "views": []
    },
    "6647a620af034d26abcd327ae02364d4": {
     "views": []
    },
    "6752222d2cba43e18f344a8db7f99d24": {
     "views": []
    },
    "6b684ba1a7c24a35ba2df77016212904": {
     "views": []
    },
    "6cea898f4aca4f1e84601f843e337238": {
     "views": []
    },
    "6f8d1e87fd60462a89d693b2f3b5f007": {
     "views": []
    },
    "74078646a5eb4047b40370a0ab8b6b30": {
     "views": []
    },
    "745b0c79ff3040788ea952fce9c7d607": {
     "views": []
    },
    "757c9b805eb7445bac9a7f141f87e45f": {
     "views": []
    },
    "76ced68e19a742e8976dbfd4e8594a1a": {
     "views": []
    },
    "783bb5e7538d4d9d8315e2698024b353": {
     "views": []
    },
    "794993d66efe4ab29a8d35aad8cfe079": {
     "views": []
    },
    "8375e24bae7541528d7cdc0f379d1d4c": {
     "views": []
    },
    "8554945ec15041a7bf8004dbc3fc5f11": {
     "views": []
    },
    "878a34e26cce4f18bb8232a682ebe964": {
     "views": []
    },
    "8921a75116a549198eb7b7f4a24ab672": {
     "views": []
    },
    "909f4504f0b049bda8b641defa177062": {
     "views": []
    },
    "910b9d32a3fb45ec99da1f9df1add816": {
     "views": []
    },
    "9d15ce601cd34f0699b7a7a0ce1d17dc": {
     "views": []
    },
    "a26638c9fee247b3891aac027a0918cc": {
     "views": []
    },
    "a9d2bf44a3ad447bb3eecde71363c198": {
     "views": []
    },
    "ad366bf4c95f4cdba62d47ba9501efc9": {
     "views": []
    },
    "ad8e1842ec314a94b6ed4b62c4c0a450": {
     "views": []
    },
    "af525094db304d2a812ae1312b00889b": {
     "views": []
    },
    "b0697c4343da491f9a35bf02681dad8f": {
     "views": []
    },
    "b07ff307919e4268bc8bec8379c47a5d": {
     "views": []
    },
    "b0e85c726ca141079333afb27edc63d4": {
     "views": []
    },
    "bdcc1e5df7a8432b9f40d8249a46f90a": {
     "views": []
    },
    "be1065f37fa24e818d31c3bb075947a3": {
     "views": []
    },
    "c296c8df2f734e268c6c1204536e7142": {
     "views": []
    },
    "c4bfd3e447f0426da144b76abc202129": {
     "views": []
    },
    "cced93184d4445218a2b14567579333d": {
     "views": []
    },
    "d5bd2e4d5f85482e9345f3a7a69380d0": {
     "views": []
    },
    "d798fa64e8be4a7d9ec1cbeece3b1be9": {
     "views": []
    },
    "d7aec0d6d05f442b991ab40af944811d": {
     "views": []
    },
    "db469cea2c8e4180bf6890de80329c1d": {
     "views": []
    },
    "e671857510c54634b6f0fa55bf1fa228": {
     "views": []
    },
    "ebf52deafaf64b0c826533dafdf993c0": {
     "views": []
    },
    "ed1e5439da9c41199a7bbbda21b556f8": {
     "views": []
    },
    "f585cf5db5024280af5b567f0e4fd771": {
     "views": []
    },
    "f6ba8f8800af47adabed847063bda8db": {
     "views": []
    },
    "f9bae72f14e44705b5c38a3ddc69fee8": {
     "views": []
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
