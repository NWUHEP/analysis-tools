{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bias studies with full systematics\n",
    "\n",
    "To assess the impact of various sources of systematic, we will rely on an Asimov dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/naodell/work/wbr/analysis\n",
      "{\n",
      "  \"shell_port\": 45759,\n",
      "  \"iopub_port\": 43783,\n",
      "  \"stdin_port\": 35009,\n",
      "  \"control_port\": 44465,\n",
      "  \"hb_port\": 46823,\n",
      "  \"ip\": \"127.0.0.1\",\n",
      "  \"key\": \"94b4cf33-d67d0aa6b745c60dd62dadb1\",\n",
      "  \"transport\": \"tcp\",\n",
      "  \"signature_scheme\": \"hmac-sha256\",\n",
      "  \"kernel_name\": \"\"\n",
      "}\n",
      "\n",
      "Paste the above JSON into a file, and connect with:\n",
      "    $> jupyter <app> --existing <file>\n",
      "or, if you are local, you can connect with just:\n",
      "    $> jupyter <app> --existing kernel-f3afdb77-1936-4582-b005-c0b4c99f41ac.json\n",
      "or even just:\n",
      "    $> jupyter <app> --existing\n",
      "if this is the most recent Jupyter kernel you have started.\n"
     ]
    }
   ],
   "source": [
    "## imports and configuration\n",
    "%cd '/home/naodell/work/wbr/analysis'\n",
    "#%load_ext autoreload\n",
    "\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import poisson, norm, chi2\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import scripts.plot_tools as pt\n",
    "import scripts.fit_helpers as fh\n",
    "from nllfit.nllfitter import ScanParameters\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "rc_params = {\n",
    "             'figure.figsize': (10, 10),\n",
    "             'axes.labelsize': 20,\n",
    "             'axes.facecolor': 'white',\n",
    "             'axes.titlesize':'x-large',\n",
    "             'legend.fontsize': 20,\n",
    "             'xtick.labelsize':20,\n",
    "             'ytick.labelsize':20,\n",
    "             'font.size':18,\n",
    "             'font.sans-serif':['Arial', 'sans-serif'],\n",
    "             'mathtext.sf':'Arial',\n",
    "             'lines.markersize':8.,\n",
    "             'lines.linewidth':2.5,\n",
    "            }\n",
    "matplotlib.rcParams.update(rc_params)\n",
    "\n",
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# configure, get the input data, and do any additional processing that is needed\n",
    "input_dir  = f'local_data/templates/test_new/'\n",
    "processes = ['ttbar', 't', 'ww', 'wjets', 'zjets_alt', 'diboson', 'fakes'] \n",
    "selections = [\n",
    "              'ee', 'emu', 'mumu',  \n",
    "              'mutau', 'etau', \n",
    "              'mu4j', 'e4j'\n",
    "             ]\n",
    "\n",
    "# initialize fit data\n",
    "fit_data = fh.FitData(input_dir, selections, processes, process_cut=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5351008be2e541e496105131142330c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205.77467961689655 191.33687022539215 189.98604930419074 0.10781761480184984 [0.107  0.108  0.1083 0.6767]\n",
      "183.52666630575416 173.77743076591935 172.04847027970513 0.1079376678398209 [0.107  0.1084 0.1069 0.6777]\n",
      "200.8811099336991 188.16952681067642 187.11497197441207 0.10816705270010209 [0.1078 0.1081 0.1096 0.6745]\n",
      "214.21979582403605 197.35369378218013 196.78358915403834 0.10815085282409044 [0.1077 0.1082 0.1088 0.6753]\n",
      "192.1878522972769 176.17239537816397 175.1954401753372 0.10871252113840822 [0.1086 0.1085 0.1103 0.6726]\n",
      "162.80938307646065 144.64374237576556 144.5211350045541 0.10866307810043192 [0.1084 0.1088 0.1083 0.6745]\n",
      "204.7692473451037 190.68159182222072 190.3277900257286 0.10771972606148505 [0.1074 0.1078 0.1083 0.6765]\n",
      "191.0358618648506 172.22085427959425 171.62442059822763 0.10877955164610252 [0.1084 0.1088 0.1096 0.6732]\n",
      "186.94299387313413 171.29508992957037 187.75127739455962 0.10765529740543568 [0.108 0.108 0.108 0.676]\n",
      "174.52433095047806 157.19844129317326 156.91329992806806 0.10690341742200812 [0.1069 0.107  0.106  0.68  ]\n",
      "206.98549092516637 180.41829395822953 180.37380300973763 0.10839514830818334 [0.1086 0.1083 0.1084 0.6747]\n",
      "194.59778455634603 178.44666590101048 178.1192606171371 0.10779198621195214 [0.1078 0.1079 0.1069 0.6774]\n",
      "206.6080294659384 190.93185919970207 190.26011974422192 0.10844498035095083 [0.1083 0.1084 0.1097 0.6737]\n",
      "182.79166778987891 169.80613962267512 168.70636062569005 0.10812599097771929 [0.1073 0.1084 0.1078 0.6764]\n",
      "158.57754115525984 147.00795392660987 146.5654156149573 0.10757674630112656 [0.1071 0.1077 0.1077 0.6775]\n",
      "186.59101589838315 174.70688872835638 172.9855210873272 0.10822947459352333 [0.1085 0.1079 0.1103 0.6733]\n",
      "190.52294790176535 181.1309189355116 180.19743856002324 0.10807472374696532 [0.1086 0.1078 0.1092 0.6744]\n",
      "192.91867061509575 167.25198242512053 166.9598047390794 0.10739383625459606 [0.1075 0.1072 0.1082 0.677 ]\n",
      "200.97227245561635 187.14395354218945 187.04068331380543 0.1087991121487002 [0.1087 0.1089 0.1084 0.6741]\n",
      "175.02432182924943 163.1603140685654 163.1622766599586 0.10835672543081462 [0.1084 0.1084 0.1083 0.675 ]\n",
      "193.67818384414508 176.8605706515894 175.79031561731776 0.10774525423327734 [0.1075 0.1076 0.1092 0.6757]\n",
      "162.84355538310683 145.75720991096208 143.0514409106401 0.10766400296193321 [0.1079 0.1079 0.1051 0.6791]\n",
      "181.80802118373384 169.32439859495776 168.3168372168883 0.1084058395763509 [0.1088 0.1084 0.1071 0.6756]\n",
      "166.08468906178447 150.24524066754162 166.50069578367587 0.10827796851710417 [0.108 0.108 0.108 0.676]\n",
      "169.17918295835057 152.25540390249319 151.70685029532183 0.10776189786103664 [0.1072 0.108  0.1075 0.6773]\n",
      "176.6307200518819 158.10384757001773 156.66406111816957 0.10808033202977028 [0.1081 0.1083 0.1061 0.6775]\n",
      "197.4651159431255 183.8109264364477 183.40135454755685 0.1083748874671986 [0.1079 0.1085 0.1085 0.6751]\n",
      "161.26299712316887 147.14503499098657 144.2628546679503 0.10776362928412093 [0.1074 0.1075 0.1103 0.6748]\n",
      "180.6230158515715 166.4289801934463 165.81445504417627 0.10795541963805001 [0.1076 0.1083 0.1068 0.6774]\n",
      "195.25077819458258 172.78690460443082 172.67754928133067 0.10837121949676716 [0.1083 0.1085 0.1078 0.6754]\n",
      "203.80371086586902 188.33009954336387 187.67482373569732 0.10753196539591667 [0.1069 0.1078 0.1072 0.6781]\n",
      "181.52009927565157 166.3761110410757 165.89761360343917 0.10816347161859254 [0.1076 0.1083 0.1081 0.676 ]\n",
      "172.1169475643335 154.97514745970818 154.16854747423753 0.10809419261708068 [0.1085 0.1081 0.107  0.6764]\n",
      "186.1373848715884 171.95246616100064 169.0904018468798 0.10820409775475326 [0.1076 0.1081 0.1105 0.6738]\n",
      "184.00913069805452 169.81353766961664 169.57566853601153 0.10753595302833371 [0.1072 0.1077 0.1071 0.678 ]\n",
      "170.4799771547592 160.82080220401187 160.5877760444887 0.10867803857295259 [0.109  0.1085 0.1091 0.6734]\n",
      "181.45350365855546 170.69373467722917 169.8231212964928 0.10795563615533375 [0.1085 0.1079 0.107  0.6766]\n",
      "187.14175403806843 171.5527482126306 170.55971403031106 0.10823862688518515 [0.1075 0.1085 0.1083 0.6758]\n",
      "192.47486669452715 175.03708598025585 174.58449776826333 0.10766519545734045 [0.1075 0.1076 0.1087 0.6762]\n",
      "174.51345897314764 161.00882851945343 160.57141744734835 0.10809205693208991 [0.1086 0.1079 0.1083 0.6752]\n",
      "173.4824645240936 156.91769876177256 156.52784388765696 0.10740735485298941 [0.1075 0.1075 0.1064 0.6785]\n",
      "180.69888983147726 171.74619941945033 171.3668426929318 0.107735061637106 [0.1079 0.1075 0.1088 0.6758]\n",
      "184.5759104845993 170.7658956534148 169.40082747467898 0.10854460386292177 [0.1092 0.1082 0.1099 0.6727]\n",
      "195.58587017353832 183.24689483897205 182.17614622816296 0.1083077835615784 [0.1083 0.1081 0.11   0.6736]\n",
      "194.84895967081198 176.32965233234083 175.01630493607524 0.10817805002504412 [0.1078 0.1081 0.1098 0.6743]\n",
      "172.48870672742387 155.0012620468235 154.38199274273904 0.10823532885456912 [0.1088 0.1081 0.108  0.6751]\n",
      "197.96256143112757 184.92583810665863 183.29460711580467 0.10860940055888398 [0.1082 0.1085 0.1103 0.673 ]\n",
      "211.95008100601498 195.56826207087352 194.93189284658132 0.10866230262387641 [0.1086 0.1089 0.1073 0.6753]\n",
      "215.70186686043394 198.817137429301 197.93366403090144 0.10760070208384394 [0.1079 0.1076 0.1063 0.6782]\n",
      "180.15196154349644 169.2361856756171 167.36019115488833 0.1085671008855744 [0.1089 0.1082 0.1109 0.6721]\n",
      "186.07093311815484 167.2702827368215 166.92660862096344 0.10811986835414525 [0.1084 0.1081 0.1074 0.6761]\n",
      "191.8285185870471 180.132164892718 180.07833488289018 0.10871073069864624 [0.1089 0.1087 0.1087 0.6737]\n",
      "175.07885109635876 162.1387750665658 162.12710702349003 0.10709265024950615 [0.107  0.1071 0.1071 0.6788]\n",
      "185.59139442625747 169.50145904091704 168.96904177583085 0.10772987152969676 [0.1076 0.1076 0.1089 0.6759]\n",
      "189.9769960188872 180.48848955699714 179.41996792533493 0.10885587866851401 [0.1081 0.1091 0.1089 0.674 ]\n",
      "189.72235318261454 177.46834088878282 177.2711255994678 0.10734185347725143 [0.1077 0.1073 0.1072 0.6778]\n",
      "192.3639532630538 176.35973890895227 175.06819529240016 0.10782237479547067 [0.1073 0.1082 0.1064 0.6781]\n",
      "195.84378620906287 186.06901405123148 183.8613350779597 0.1079931819985279 [0.1078 0.1084 0.1056 0.6783]\n",
      "163.84164503793815 148.89851374044173 148.29777302555723 0.10735708198467045 [0.1079 0.1072 0.1069 0.678 ]\n",
      "199.95765386347065 189.28448047616774 187.25510803987035 0.10798065686383661 [0.1079 0.1077 0.1102 0.6742]\n",
      "197.79630670610715 182.56852229924732 181.1251393628416 0.10861879201096244 [0.1095 0.1084 0.1081 0.6739]\n",
      "181.7787800430914 159.5181516089762 158.32621442855432 0.1081860038378482 [0.1086 0.1078 0.1098 0.6738]\n",
      "189.72739486847163 168.80961337802984 168.5492482832607 0.10786937224499736 [0.1079 0.1078 0.1087 0.6756]\n",
      "171.3099674568954 163.7400842166603 163.44444778318723 0.10777430398721694 [0.1081 0.1077 0.1073 0.6769]\n",
      "175.50204901519334 160.75185190588127 159.87780932743877 0.10814908175029435 [0.1082 0.1083 0.1066 0.6769]\n",
      "163.2998821805968 148.2414512554542 148.10296370186575 0.10791375872159675 [0.1076 0.108  0.108  0.6764]\n",
      "183.5476466849672 168.15506989239233 183.96076529557365 0.1077625161977516 [0.108 0.108 0.108 0.676]\n",
      "155.9852623604274 139.96316257370265 139.95176039374488 0.10790634778142602 [0.108  0.1079 0.108  0.6761]\n",
      "190.88120271914343 173.36074880550754 172.84109010402238 0.10881905277270194 [0.1083 0.109  0.1088 0.6739]\n",
      "194.27674890412354 183.545094073831 181.3060594346866 0.10748989825467055 [0.1063 0.1079 0.1066 0.6792]\n",
      "181.87516907882346 169.93812543232244 168.16060865725962 0.10777356519470402 [0.1078 0.1074 0.1099 0.6749]\n",
      "167.8535450286027 151.75933201363597 151.0559427405209 0.10762393051329654 [0.1082 0.1075 0.1075 0.6768]\n",
      "190.84852535599384 166.75186197554683 166.0549789495652 0.10771363453087543 [0.1076 0.1076 0.109  0.6758]\n",
      "210.41667036024788 188.523404692737 188.06688099936233 0.10915762288289782 [0.1087 0.1094 0.1085 0.6735]\n",
      "142.14071274059296 130.86399433580635 130.48586160742363 0.1080838247981292 [0.1077 0.1083 0.1076 0.6764]\n",
      "190.2926273810021 175.87373032888627 175.358589977263 0.10771366202557507 [0.1074 0.1079 0.1067 0.678 ]\n",
      "181.5904943833939 168.5468875806638 167.7115721490701 0.10822710900588332 [0.1086 0.1082 0.1071 0.6761]\n",
      "189.88132302963757 176.15797756121626 176.0728610822723 0.10787937665495415 [0.1078 0.108  0.1074 0.6769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204.82432593226903 185.40665799733145 182.92140275855672 0.10723995930880849 [0.1072 0.1076 0.1049 0.6804]\n",
      "200.94199765640943 186.34206360682538 186.2990386549659 0.1083305637132189 [0.1084 0.1083 0.1087 0.6747]\n",
      "195.8651885032593 180.70884674190472 180.31377028911544 0.10768884454922603 [0.1082 0.1075 0.1077 0.6766]\n"
     ]
    }
   ],
   "source": [
    "# generate toy data and fit w/ alt and null hypotheses\n",
    "params = fit_data._parameters\n",
    "params_pre = fit_data.get_params_init().values\n",
    "nparams = params.shape[0] \n",
    "\n",
    "# test systematic uncertainties\n",
    "pval, perr = params['val_init'].values, params['err_init'].values\n",
    "#prand = pval[:4] + np.random.randn(4, ntoys).T*perr[:4] \n",
    "\n",
    "# fit toy data\n",
    "ntoys = 100\n",
    "nll_null, nll_alt = [], []\n",
    "params_null, params_alt = [], []\n",
    "for itoy in tqdm_notebook(range(ntoys)):\n",
    "    \n",
    "    # generate toy data\n",
    "    sample = dict()\n",
    "    for category in fit_data._model_data.keys():\n",
    "        model_val, model_var = fit_data.mixture_model(params_pre, category)\n",
    "        sample[category] = poisson.rvs(model_val), model_var #+ np.sqrt(model_var)*np.random.randn(model_var.size)\n",
    "     \n",
    "    # null hypothesis: lepton universality\n",
    "    pinit = np.concatenate([[params_pre[0]], params_pre[4:]])\n",
    "    objective_null = partial(fh.objective_lu, objective = fit_data.objective)\n",
    "    result_null = minimize(objective_null, pinit,\n",
    "                           method = 'SLSQP',\n",
    "                           options = dict(maxiter=500, ftol=1e-6, disp=False),\n",
    "                           args = (sample)\n",
    "                          )\n",
    "    \n",
    "    # alt hypothesis: independent bf\n",
    "    pinit = params_pre\n",
    "    result_alt = minimize(fit_data.objective, pinit,\n",
    "                          method = 'SLSQP',\n",
    "                          options = dict(maxiter=500, ftol=1e-6, disp=False),\n",
    "                          args = (sample)\n",
    "                         )\n",
    "    \n",
    "    print(fit_data.objective(params_pre, sample), result_null.fun, result_alt.fun, result_null.x[0], result_alt.x[:4])\n",
    "    if result_alt.success and result_null.success:\n",
    "        nll_null.append(result_null.fun)\n",
    "        params_null.append(result_null.x)\n",
    "        nll_alt.append(result_alt.fun)\n",
    "        params_alt.append(result_alt.x)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "nll_null = np.array(nll_null)\n",
    "nll_alt = np.array(nll_alt)\n",
    "params_null = np.array(params_null)\n",
    "params_alt = np.array(params_alt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# make some plots\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10), facecolor='white')\n",
    "\n",
    "x = np.linspace(0, 10, 1000)\n",
    "ax.hist(2*(nll_null - nll_alt), bins=x[::50], density=True)\n",
    "ax.plot(x, chi2.pdf(x, 2), 'r--')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "29px",
    "width": "251px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "49px",
    "left": "0px",
    "right": "1493.87px",
    "top": "90.9965px",
    "width": "242px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "widgets": {
   "state": {
    "012f8bbe2fdb410dae6e2cde9d7fe5cb": {
     "views": []
    },
    "080556076f174648bddf64f17a54c523": {
     "views": []
    },
    "0ad83b5f67484ae5b8fd8dd43ccc39bd": {
     "views": []
    },
    "15acd81a9adc493683d9b63813f000bf": {
     "views": []
    },
    "1840cb6fded848b4ae95ec8d3db15ab2": {
     "views": []
    },
    "1dd83f822e074642ae4255b15ee661cf": {
     "views": []
    },
    "1e71a878e6474912a0efc497ecc5d65b": {
     "views": []
    },
    "2022ed83777b4963b630b5c46239e218": {
     "views": []
    },
    "21c4c57bfc48495194663e6a4fbac488": {
     "views": []
    },
    "22c45c75435348c0b9501d493d69fdca": {
     "views": []
    },
    "2635f668a1af4a9db2642e705d7c73ff": {
     "views": []
    },
    "2ad5ddd9347e451b9290e5b4179ab9a2": {
     "views": []
    },
    "2c062b5778024117984822b63b0593d7": {
     "views": []
    },
    "2f5eab2f6fb24192b76a5ffe99195d44": {
     "views": []
    },
    "31632517325046e8b0cb62e4f4ed2480": {
     "views": []
    },
    "3562b97192ed4d42bbab17f77c290f6b": {
     "views": []
    },
    "38a7cc053723492b921cf9f084ed243c": {
     "views": []
    },
    "3b5750b20e1745879ca0f965aad7b614": {
     "views": []
    },
    "3f1cbabbe2694a9dabe3f1c2e09d0ee2": {
     "views": []
    },
    "3fab6a26a70c4238a668a46d4dc88bf6": {
     "views": []
    },
    "3fb3c7a25e954a4888996976fa107737": {
     "views": []
    },
    "415db64fbc574daea8457ab600392f09": {
     "views": []
    },
    "4463de406b4645a4b562fe7917380ff9": {
     "views": []
    },
    "487e5450b5a24507932709f1fa8f59c1": {
     "views": []
    },
    "48aba73013e74e71927f71d42fb44d14": {
     "views": []
    },
    "4a19ad30f77e4fe6a2c84c8b62378a47": {
     "views": []
    },
    "4bc83ff5270d41679d76d26cdded8313": {
     "views": []
    },
    "4bdd9dd5c5c64646a27fa9096851458b": {
     "views": []
    },
    "5014cd42705f45178d5e6eeffd70f119": {
     "views": []
    },
    "5259b340b68e4fdb97fb4eaf9d98d954": {
     "views": []
    },
    "5986ef5b605a42aca10bc5834529ee06": {
     "views": []
    },
    "5c1aa44589a140eb9709734c843abde6": {
     "views": []
    },
    "600cd9ca4f4c46d4ad6fe57df107675a": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "61fe369ebdd14eaa89de110f6186e6b7": {
     "views": []
    },
    "62ac836017ae47a38f8fde806c5ec9b7": {
     "views": []
    },
    "632ccbfabe91405aa1c5a77c9ea754db": {
     "views": []
    },
    "66175f618ea5472baac618f998d2c06c": {
     "views": []
    },
    "6647a620af034d26abcd327ae02364d4": {
     "views": []
    },
    "6752222d2cba43e18f344a8db7f99d24": {
     "views": []
    },
    "6b684ba1a7c24a35ba2df77016212904": {
     "views": []
    },
    "6cea898f4aca4f1e84601f843e337238": {
     "views": []
    },
    "6f8d1e87fd60462a89d693b2f3b5f007": {
     "views": []
    },
    "74078646a5eb4047b40370a0ab8b6b30": {
     "views": []
    },
    "745b0c79ff3040788ea952fce9c7d607": {
     "views": []
    },
    "757c9b805eb7445bac9a7f141f87e45f": {
     "views": []
    },
    "76ced68e19a742e8976dbfd4e8594a1a": {
     "views": []
    },
    "783bb5e7538d4d9d8315e2698024b353": {
     "views": []
    },
    "794993d66efe4ab29a8d35aad8cfe079": {
     "views": []
    },
    "8375e24bae7541528d7cdc0f379d1d4c": {
     "views": []
    },
    "8554945ec15041a7bf8004dbc3fc5f11": {
     "views": []
    },
    "878a34e26cce4f18bb8232a682ebe964": {
     "views": []
    },
    "8921a75116a549198eb7b7f4a24ab672": {
     "views": []
    },
    "909f4504f0b049bda8b641defa177062": {
     "views": []
    },
    "910b9d32a3fb45ec99da1f9df1add816": {
     "views": []
    },
    "9d15ce601cd34f0699b7a7a0ce1d17dc": {
     "views": []
    },
    "a26638c9fee247b3891aac027a0918cc": {
     "views": []
    },
    "a9d2bf44a3ad447bb3eecde71363c198": {
     "views": []
    },
    "ad366bf4c95f4cdba62d47ba9501efc9": {
     "views": []
    },
    "ad8e1842ec314a94b6ed4b62c4c0a450": {
     "views": []
    },
    "af525094db304d2a812ae1312b00889b": {
     "views": []
    },
    "b0697c4343da491f9a35bf02681dad8f": {
     "views": []
    },
    "b07ff307919e4268bc8bec8379c47a5d": {
     "views": []
    },
    "b0e85c726ca141079333afb27edc63d4": {
     "views": []
    },
    "bdcc1e5df7a8432b9f40d8249a46f90a": {
     "views": []
    },
    "be1065f37fa24e818d31c3bb075947a3": {
     "views": []
    },
    "c296c8df2f734e268c6c1204536e7142": {
     "views": []
    },
    "c4bfd3e447f0426da144b76abc202129": {
     "views": []
    },
    "cced93184d4445218a2b14567579333d": {
     "views": []
    },
    "d5bd2e4d5f85482e9345f3a7a69380d0": {
     "views": []
    },
    "d798fa64e8be4a7d9ec1cbeece3b1be9": {
     "views": []
    },
    "d7aec0d6d05f442b991ab40af944811d": {
     "views": []
    },
    "db469cea2c8e4180bf6890de80329c1d": {
     "views": []
    },
    "e671857510c54634b6f0fa55bf1fa228": {
     "views": []
    },
    "ebf52deafaf64b0c826533dafdf993c0": {
     "views": []
    },
    "ed1e5439da9c41199a7bbbda21b556f8": {
     "views": []
    },
    "f585cf5db5024280af5b567f0e4fd771": {
     "views": []
    },
    "f6ba8f8800af47adabed847063bda8db": {
     "views": []
    },
    "f9bae72f14e44705b5c38a3ddc69fee8": {
     "views": []
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
