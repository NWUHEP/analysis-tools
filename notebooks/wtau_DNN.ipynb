{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/naodell/work/z_plus_jpsi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.11/01\n"
     ]
    }
   ],
   "source": [
    "# imports and setup\n",
    "%cd '/home/naodell/work/z_plus_jpsi'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.style.use('default')\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from root_pandas import read_root\n",
    "\n",
    "import scripts.plot_tools as pt\n",
    "import scripts.nn_helpers as nnhelper\n",
    "\n",
    "#%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataframes:   0%|                      | 0.00/10.0 [00:00<?, ?it/s]/opt/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "Loading dataframes: 100%|███████████████| 10.0/10.0 [00:04<00:00, 1.32it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'ttbar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e636b86638cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m                    )\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mdf_top\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ttbar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;31m#df_zjets = dm.get_dataframe('zjets')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m#df_fakes = dm.get_dataframe('data_ss')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/naodell/work/z_plus_jpsi/scripts/plot_tools.py\u001b[0m in \u001b[0;36mget_dataframe\u001b[0;34m(self, dataset_name, condition)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcondition\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ttbar'"
     ]
    }
   ],
   "source": [
    "### get the data and prepare labels\n",
    "disc_features = ['n_jets', 'n_fwdjets', 'n_bjets'] \n",
    "cont_features = [\n",
    "                 'lepton1_pt', 'lepton1_eta', 'lepton1_phi', 'lepton1_iso',              \n",
    "                 'lepton2_pt', 'lepton2_eta', 'lepton2_phi', 'lepton2_iso',              \n",
    "                 #'lepton1_d0', 'lepton1_dz',\n",
    "                 #'lepton2_d0', 'lepton2_dz',\n",
    "    \n",
    "                 'dilepton1_delta_eta', 'dilepton1_delta_phi', 'dilepton1_delta_r',\n",
    "                 'dilepton1_mass', 'dilepton1_pt', 'dilepton1_eta', 'dilepton1_phi',\n",
    "                 'dilepton1_pt_asym',\n",
    "                                                                                         \n",
    "                 'met_mag', 'met_phi', 'ht_mag', 'ht_phi',\n",
    "                 'jet1_pt', 'jet1_eta', 'jet1_phi', 'jet1_tag',                                     \n",
    "                 'jet2_pt', 'jet2_eta', 'jet2_phi', 'jet2_tag',                                     \n",
    "                 'jet_delta_eta', 'jet_delta_phi', 'jet_delta_r',                        \n",
    "                 'dijet_mass', 'dijet_pt', 'dijet_eta', 'dijet_phi',                     \n",
    "                                                                                         \n",
    "                 'lepton1_j1_mass', 'lepton1_j1_pt',\n",
    "                 'lepton1_j1_delta_r', 'lepton1_j1_delta_eta', 'lepton1_j1_delta_phi',\n",
    "                 'lepton2_j1_mass', 'lepton2_j1_pt',\n",
    "                 'lepton2_j1_delta_r', 'lepton2_j1_delta_eta', 'lepton2_j1_delta_phi',\n",
    "                 'lepton1_j2_mass', 'lepton1_j2_pt',\n",
    "                 'lepton1_j2_delta_r', 'lepton1_j2_delta_eta', 'lepton1_j2_delta_phi',\n",
    "                 'lepton2_j2_mass', 'lepton2_j2_pt',\n",
    "                 'lepton2_j2_delta_r', 'lepton2_j2_delta_eta', 'lepton2_j2_delta_phi',\n",
    "    \n",
    "                 'dilepton_j1_mass', 'dilepton_j1_pt',                                   \n",
    "                 'dilepton_j1_delta_r', 'dilepton_j1_delta_eta', 'dilepton_j1_delta_phi',\n",
    "                 'dilepton_j2_mass', 'dilepton_j2_pt',                                   \n",
    "                 'dilepton_j2_delta_r', 'dilepton_j2_delta_eta', 'dilepton_j2_delta_phi',\n",
    "                 'four_body_mass',                                                       \n",
    "                 'four_body_delta_r', 'four_body_delta_eta', 'four_body_delta_phi',      \n",
    "                ]\n",
    "\n",
    "cuts = 'lepton1_pt > 10 and abs(lepton1_eta) < 2.4 \\\n",
    "        and lepton2_pt > 15 and abs(lepton2_eta) < 2.5 \\\n",
    "        and lepton1_reliso < 0.15 \\\n",
    "        and lepton1_q != lepton2_q \\\n",
    "        and 12 < dilepton1_mass \\\n",
    "        and n_jets + n_bjets >= 2 \\\n",
    "        and weight >= 0' # need to figure out why I have negative weights (no I don't use generator weights)\n",
    "\n",
    "datasets    = [\n",
    "               #'muon_2016B', 'muon_2016C', 'muon_2016D',\n",
    "               #'muon_2016E', 'muon_2016F', 'muon_2016G', 'muon_2016H',\n",
    "               #'electron_2016B', 'electron_2016C', 'electron_2016D',\n",
    "               #'electron_2016E', 'electron_2016F', 'electron_2016G', 'electron_2016H',\n",
    "               'mueg_2016B', 'mueg_2016C', 'mueg_2016D',\n",
    "               'mueg_2016E', 'mueg_2016F', 'mueg_2016G', 'mueg_2016H',\n",
    "\n",
    "               'ttbar_lep', 't_tw', 'tbar_tw',             \n",
    "               #'zjets_m-50',  'zjets_m-10to50',  \n",
    "               #'data_ss'\n",
    "               ] \n",
    "\n",
    "dm = pt.DataManager(input_dir     = 'data/flatuples/emu_2016',\n",
    "                    dataset_names = datasets,\n",
    "                    selection     = 'emu',\n",
    "                    period        = 2016,\n",
    "                    scale         = 36.4e3,\n",
    "                    cuts          = cuts\n",
    "                   )\n",
    "\n",
    "df_top = pd.concat([dm.get_dataframe('ttbar'), dm.get_dataframe('t')])\n",
    "#df_zjets = dm.get_dataframe('zjets')\n",
    "#df_fakes = dm.get_dataframe('data_ss')\n",
    "#df_data  = dm.get_dataframe('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "\n",
    "# reweight ss selection to corresond to probability of sampling this event (I don't think this is right)\n",
    "#n_evt = (df_zjets.weight.sum() + df_top.weight.sum() + df_fakes.weight.sum())\n",
    "#df_fakes['weight'] *= 1./n_evt\n",
    "\n",
    "# split top events based on decay mode\n",
    "df_top.loc[(abs(df_top.lepton1_mother) == 24) & (abs(df_top.lepton2_mother) == 24), 'label'] = 'emu'\n",
    "df_top.loc[(abs(df_top.lepton1_mother) == 15) & (abs(df_top.lepton2_mother) == 24), 'label'] = 'etau'\n",
    "df_top.loc[(abs(df_top.lepton1_mother) == 24) & (abs(df_top.lepton2_mother) == 15), 'label'] = 'mutau'\n",
    "df_top.loc[(abs(df_top.lepton1_mother) == 15) & (abs(df_top.lepton2_mother) == 15), 'label'] = 'tautau'\n",
    "\n",
    "# combine dataframes, group non-top backgrounds, and drop events where gen matching failed\n",
    "df_top = df_top.query('label != \"ttbar\" and label!=\"t\"')\n",
    "#df_zjets.label = 'bg'\n",
    "#df_fakes.label = 'bg'\n",
    "#df_combined = pd.concat([df_top, df_zjets, df_fakes])\n",
    "df_combined = df_top\n",
    "\n",
    "# set feature ranges and fill underflow/overflow bins; scale features to lie between 0 and 1; binarize discrete variables\n",
    "df_trans = nnhelper.preprocess_data(df_combined, cont_features, disc_features, dm.get_bounds_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot the transformed variables\n",
    "if False:\n",
    "    df_trans.hist(cont_features, bins=50, histtype='stepfilled', figsize=(25, 25))\n",
    "    plt.yscale('log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample from dataframe according to event weights; split into testing and training sets\n",
    "n_total   = df_trans.shape[0]\n",
    "split     = int(0.8*n_total)\n",
    "\n",
    "df_sample = df_trans.sample(frac=1)#.reset_index()\n",
    "\n",
    "# training sample\n",
    "df_train = df_sample[:split] \n",
    "x_train = df_train.drop(['label', 'weight'], axis=1).values\n",
    "y_train = df_train['label'].values\n",
    "\n",
    "df_test = df_sample[split:]\n",
    "x_test = df_test.drop(['label', 'weight'], axis=1).values\n",
    "y_test = df_test['label'].values\n",
    "\n",
    "# create one hot encoding for category labels\n",
    "label_enc = preprocessing.LabelBinarizer()\n",
    "label_enc.fit(y_train)\n",
    "onehot_enc = preprocessing.OneHotEncoder(sparse=False)\n",
    "y_train = label_enc.transform(y_train)\n",
    "y_test  = label_enc.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "#model = nnhelper.initialize_model(x_train.shape[1], y_train.shape[1])\n",
    "model = Sequential()                                                                 \n",
    "model.add(Dense(128, activation='relu', input_dim=x_train.shape[1]))                       \n",
    "#model.add(Dropout(0.5))                                                             \n",
    "model.add(Dense(64, activation='relu'))                                             \n",
    "#model.add(Dropout(0.5))                                                             \n",
    "model.add(Dense(32, activation='relu'))                                             \n",
    "#model.add(Dropout(0.5))                                                             \n",
    "model.add(Dense(16, activation='relu'))                                             \n",
    "#model.add(Dropout(0.5))                                                             \n",
    "model.add(Dense(y_train.shape[1], activation='softmax'))                                  \n",
    "                                                                                     \n",
    "sgd = SGD(lr=0.1, decay=1e-5, momentum=0.9, nesterov=True)                          \n",
    "model.compile(loss='categorical_crossentropy',                                       \n",
    "              optimizer=sgd,                                                         \n",
    "              metrics=['categorical_accuracy'])#, 'fmeasure', 'precision', 'recall'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs = 50,\n",
    "                    batch_size = 64,\n",
    "                    #sample_weight = df_train.weight.values,\n",
    "                    validation_split = 0.20)\n",
    "model.evaluate(x_test, y_test)\n",
    "model.save('data/w_to_tau_DNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get prediciton, calculate efficiencies\n",
    "#l = ['score_bg', 'score_emu', 'score_etau', 'score_mutau', 'score_tautau']\n",
    "l = ['score_emu', 'score_etau', 'score_mutau', 'score_tautau']\n",
    "df_pred = pd.DataFrame(model.predict(x_test), columns=l)\n",
    "df_pred = pd.concat([df_pred, df_test.reset_index()], axis=1)\n",
    "score_corr = df_pred[l].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pairplots of NN scores by categories\n",
    "sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "g = sns.PairGrid(df_pred[:10000], vars=l, \n",
    "                 hue='label', \n",
    "                 hue_order=['emu', 'mutau', 'etau', 'tautau'], #'bg'],\n",
    "                 hue_kws=dict(marker=['o', 's', 'D', '8', '1']),\n",
    "                 palette='husl',\n",
    "                 size = 5\n",
    "                )\n",
    "g.map_diag(plt.hist, stacked=False, histtype='step', normed=False, linewidth=3)\n",
    "g.map_offdiag(plt.scatter, linewidths=0.5, edgecolor=\"w\", s=85, alpha=1)\n",
    "#for i, j in zip(*np.triu_indices_from(g.axes, 1)):\n",
    "#    g.axes[i, j].set_visible(False)\n",
    "\n",
    "legend_labels = [ r'$W\\rightarrow\\mu, W\\rightarrow e$', \n",
    "                 r'$W\\rightarrow\\mu, \\tau\\rightarrow e$', \n",
    "                 r'$\\tau\\rightarrow\\mu, W\\rightarrow e$', \n",
    "                 r'$\\tau\\rightarrow\\mu, \\tau\\rightarrow e$',\n",
    "                 #r'background', \n",
    "                ]\n",
    "plt.legend(legend_labels, \n",
    "           bbox_to_anchor=(1.05, 1), \n",
    "           loc=2, \n",
    "           borderaxespad=0., \n",
    "           fontsize=22\n",
    "          )\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.savefig('plots/emu_nn_scorepairs.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# diagonal entries\n",
    "labels = ['tautau', 'etau', 'mutau', 'emu']\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,10))\n",
    "axes[0][0].hist([df_pred[df_pred.label == n].score_emu for n in labels], \n",
    "                bins=25, \n",
    "                stacked=True, \n",
    "                histtype='stepfilled', \n",
    "                linewidth=1.5,\n",
    "                alpha=0.75\n",
    "               )\n",
    "axes[0][0].set_yscale('log')\n",
    "axes[0][0].set_xlabel(r'$e+\\mu$ score')\n",
    "axes[0][0].grid()\n",
    "\n",
    "axes[0][1].hist([df_pred[df_pred.label == n].score_etau for n in labels],\n",
    "                bins=25, \n",
    "                stacked=True, \n",
    "                histtype='stepfilled', \n",
    "                linewidth=1.5,\n",
    "                alpha=0.75\n",
    "               )\n",
    "axes[0][1].legend([r'$e + \\mu$', r'$\\tau\\rightarrow e + \\mu$', r'$e + \\tau\\rightarrow\\mu$', r'$\\tau\\rightarrow e + \\tau\\rightarrow\\mu$'])\n",
    "axes[0][1].set_yscale('log')\n",
    "axes[0][1].set_xlabel(r'$e+\\tau$ score')\n",
    "axes[0][1].grid()\n",
    "\n",
    "axes[1][0].hist([df_pred[df_pred.label == n].score_mutau for n in labels], \n",
    "                bins=25, \n",
    "                stacked=True, \n",
    "                histtype='stepfilled', \n",
    "                linewidth=1.5,\n",
    "                alpha=0.75\n",
    "               )\n",
    "axes[1][0].set_yscale('log')\n",
    "axes[1][0].set_xlabel(r'$\\mu+\\tau$ score')\n",
    "axes[1][0].grid()\n",
    "\n",
    "axes[1][1].hist([df_pred[df_pred.label == n].score_tautau for n in labels], \n",
    "                bins=25, \n",
    "                stacked=True, \n",
    "                histtype='stepfilled', \n",
    "                linewidth=1.5, \n",
    "                alpha=0.75\n",
    "               )\n",
    "axes[1][1].set_yscale('log')\n",
    "axes[1][1].set_xlabel(r'$\\tau+\\tau$ score')\n",
    "axes[1][1].grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# diagonal entries\n",
    "labels = ['tautau', 'etau', 'mutau', 'emu']\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10,10))\n",
    "axes[0][0].hist([df_pred[df_pred.label == n].score_emu for n in labels], \n",
    "                bins=25, \n",
    "                normed=True, \n",
    "                histtype='step', \n",
    "                linewidth=1.5,\n",
    "                alpha=0.75\n",
    "               )\n",
    "axes[0][0].set_yscale('log')\n",
    "axes[0][0].set_xlabel(r'$e+\\mu$ score')\n",
    "axes[0][0].grid()\n",
    "\n",
    "axes[0][1].hist([df_pred[df_pred.label == n].score_etau for n in labels],\n",
    "                bins=25, \n",
    "                normed=True, \n",
    "                histtype='step', \n",
    "                linewidth=1.5,\n",
    "                alpha=0.75\n",
    "               )\n",
    "axes[0][1].legend([r'$e + \\mu$', r'$\\tau\\rightarrow e + \\mu$', r'$e + \\tau\\rightarrow\\mu$', r'$\\tau\\rightarrow e + \\tau\\rightarrow\\mu$'])\n",
    "axes[0][1].set_yscale('log')\n",
    "axes[0][1].set_xlabel(r'$e+\\tau$ score')\n",
    "axes[0][1].grid()\n",
    "\n",
    "axes[1][0].hist([df_pred[df_pred.label == n].score_mutau for n in labels], \n",
    "                bins=25, \n",
    "                normed=True, \n",
    "                histtype='step', \n",
    "                linewidth=1.5,\n",
    "                alpha=0.75\n",
    "               )\n",
    "axes[1][0].set_yscale('log')\n",
    "axes[1][0].set_xlabel(r'$\\mu+\\tau$ score')\n",
    "axes[1][0].grid()\n",
    "\n",
    "axes[1][1].hist([df_pred[df_pred.label == n].score_tautau for n in labels], \n",
    "                bins=25, \n",
    "                normed=True, \n",
    "                histtype='step', \n",
    "                linewidth=1.5, \n",
    "                alpha=0.75\n",
    "               )\n",
    "axes[1][1].set_yscale('log')\n",
    "axes[1][1].set_xlabel(r'$\\tau+\\tau$ score')\n",
    "axes[1][1].grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "4px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
