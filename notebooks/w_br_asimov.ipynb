{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# systematics with the Asimov dataset\n",
    "\n",
    "To assess the impact of various sources of systematic, we will rely on an Asimov dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/naodell/work/wbr/analysis\n"
     ]
    }
   ],
   "source": [
    "## imports and configuration\n",
    "%cd '/home/naodell/work/wbr/analysis'\n",
    "\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from scipy.optimize import minimize\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import scripts.plot_tools as pt\n",
    "import scripts.fit_helpers as fh\n",
    "from nllfit.nllfitter import ScanParameters\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "matplotlib.style.use('default')\n",
    "params = {'legend.fontsize': 20,\n",
    "          'axes.labelsize': 20,\n",
    "          'figure.figsize': (8, 8),\n",
    "          'axes.facecolor': 'white',\n",
    "          'axes.titlesize':'x-large',\n",
    "          'xtick.labelsize':18,\n",
    "          'ytick.labelsize':18,\n",
    "         }\n",
    "matplotlib.rcParams.update(params)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-97f4e3bb3eb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# initialize fit data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mfit_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFitData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/wbr/analysis/scripts/fit_helpers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, selections, feature_map)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_selections\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decay_map\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/decay_map.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selection_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_template_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselections\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/wbr/analysis/scripts/fit_helpers.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_selections\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decay_map\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/decay_map.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selection_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_template_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselections\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/wbr/analysis/scripts/fit_helpers.py\u001b[0m in \u001b[0;36m_initialize_template_data\u001b[0;34m(self, location, target, selection)\u001b[0m\n\u001b[1;32m     61\u001b[0m         '''\n\u001b[1;32m     62\u001b[0m         \u001b[0minfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{location}/{selection}_templates.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0minfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "# configure, get the input data, and do any additional processing that is needed\n",
    "input_dir  = f'data/templates/bjet_binned_test/'\n",
    "selections = [\n",
    "              'emu', \n",
    "              'mumu',  'mutau', 'mu4j',\n",
    "              'ee',  'etau', 'e4j'\n",
    "             ]\n",
    "n_selection = len(selections)\n",
    "targets    = dict(\n",
    "                  mumu  = 'lepton2_pt', \n",
    "                  ee    = 'lepton2_pt', \n",
    "                  emu   = 'trailing_lepton_pt', \n",
    "                  mutau = 'lepton2_pt', \n",
    "                  etau  = 'lepton2_pt', \n",
    "                  mu4j  = 'lepton1_pt',\n",
    "                  e4j   = 'lepton1_pt'\n",
    "                 )\n",
    "plot_labels = dict(\n",
    "                   mumu  = [r'$\\sf p_{T, \\mu}$', r'$\\mu\\mu$'],\n",
    "                   ee    = [r'$\\sf p_{T, e}$', r'$ee$'],\n",
    "                   emu   = [r'$\\sf p_{T, \\ell}$', r'$e\\mu$'],\n",
    "                   mutau = [r'$\\sf p_{T, \\tau}$', r'$\\mu\\tau$'],\n",
    "                   etau  = [r'$\\sf p_{T, \\tau}$', r'$e\\tau$'],\n",
    "                   mu4j  = [r'$\\sf p_{T, \\mu}$', r'$\\mu$ + jets'],\n",
    "                   e4j   = [r'$\\sf p_{T, e}$', r'$e$ + jets']\n",
    "                  )\n",
    "#p_labels = [r'$\\beta_{e}$', r'$\\beta_{\\mu}$', r'$\\beta_{\\tau}$', r'$\\beta_{h}$',\n",
    "#            r'$\\sf L_{int}$', \n",
    "#            r'$\\sigma_{t\\bar{t}}$',  r'$\\sigma_{z}$',  r'$\\sigma_{w}$', r'$\\sf k_{fakes}$', \n",
    "#            r'$\\sf \\epsilon_{e}$', r'$\\sf \\epsilon_{\\mu}$', r'$\\sf \\epsilon_{\\tau}$']\n",
    "\n",
    "p_labels = ['B_e', 'B_mu', 'B_tau', 'B_h', \n",
    "            'L', \n",
    "            'sigma_tt', 'sigma_tW', 'sigma_z', 'sigma_w', 'sigma_diboson', 'k_fake', \n",
    "            'trigger_e', 'trigger_mu',\n",
    "            'eff_e', 'eff_mu', 'eff_tau', \n",
    "            'pileup', \n",
    "            'escale_e', 'escale_mu', 'escale_tau', \n",
    "            'jes', 'jer', 'btag', 'mistag',\n",
    "            'fsr', 'isr', 'tune', 'hdamp', 'qcd', 'pdf'\n",
    "           ]\n",
    "\n",
    "# initial values for W branching fraction (beta_e, beta_mu, beta_tau, beta_h) and tau branching fraction (b_e, b_mu, b_h)\n",
    "br_tau    = [0.1783, 0.1741, 0.6476]\n",
    "beta_init = [0.108, 0.108, 0.108, 1 - 3*0.108] \n",
    "var_beta  = [0.0009**2, 0.0009**2, 0.0009**2, 0.0031**2]\n",
    "\n",
    "# initialize fit data\n",
    "fit_data = fh.FitData(input_dir, selections, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# generate Asimov dataset\n",
    "toy_data = dict()\n",
    "for selection in selections:\n",
    "    toy_data[selection] = dict()\n",
    "    sdata = fit_data.get_selection_data(selection)\n",
    "    for b, bdata in sdata.items():\n",
    "        if b == 0: continue\n",
    "        templates = bdata['templates']\n",
    "        \n",
    "        # signal component\n",
    "        toy_data[selection][b] = np.zeros(bdata['bins'].size - 1)\n",
    "        for sig in ['ttbar', 't', 'wjets']:\n",
    "            signal_template = list(templates[sig].values())\n",
    "            if sig == 'wjets':\n",
    "                continue\n",
    "                signal = fh.signal_mixture_model(beta_init, br_tau, signal_template, sample=False, single_w=True)[0]\n",
    "            else:\n",
    "                signal = fh.signal_mixture_model(beta_init, br_tau, signal_template, sample=False)[0]\n",
    "            toy_data[selection][b] += signal\n",
    "        \n",
    "        # background component\n",
    "        for bg in ['zjets', 'diboson', 'fakes']:\n",
    "            if bg == 'fakes' and selection not in ['mu4j', 'mutau', 'etau']:\n",
    "                continue\n",
    "\n",
    "            toy_data[selection][b] += templates[bg]['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# visualize toy data\n",
    "fig, axes = plt.subplots(2, 7, figsize=(24, 12), facecolor='white')\n",
    "for i, selection in enumerate(selections):\n",
    "    sdata = fit_data.get_selection_data(selection)\n",
    "    for j, (b, bdata) in enumerate(sdata.items()):\n",
    "        templates = bdata['templates']\n",
    "        \n",
    "        if b == 0: continue # and selection not in ['etau', 'mutau']: continue\n",
    "            \n",
    "        # get and plot the data \n",
    "        bins = bdata['bins'][:-1]\n",
    "        dx = (bins[1:] - bins[:-1])\n",
    "        dx = np.append(dx, dx[-1]) \n",
    "        x  = bins + dx/2            \n",
    "\n",
    "        ax = axes[b-1][i]\n",
    "        data = toy_data[selection][b]\n",
    "        ax.errorbar(x, data/dx, np.sqrt(data)/dx, fmt='ko', linewidth=2., markersize=5)\n",
    "        \n",
    "        # background component\n",
    "        h_bg = np.zeros(data.shape)\n",
    "        for bg_label in ['zjets', 'diboson', 'fakes']:\n",
    "            if bg_label == 'fakes' and selection not in ['mu4j', 'mutau', 'etau']:\n",
    "                continue\n",
    "            h_bg += templates[bg_label]['val']\n",
    "        \n",
    "        ## signal component\n",
    "        h_twotau   = np.zeros(h_bg.shape)\n",
    "        h_onetau  = np.zeros(h_bg.shape)\n",
    "        h_nominal = np.zeros(h_bg.shape)\n",
    "        for sig in ['ttbar', 't', 'wjets']:\n",
    "            signal_template = list(templates[sig].values())\n",
    "\n",
    "            if sig == 'wjets':\n",
    "                continue\n",
    "                h_onetau  += fh.signal_mixture_model(beta_init, br_tau, signal_template, mask=np.array([0, 0, 1, 1, 1, 0]), single_w=True)[0]\n",
    "                h_nominal += fh.signal_mixture_model(beta_init, br_tau, signal_template, single_w=True)[0]\n",
    "            else:\n",
    "                h_twotau  += fh.signal_mixture_model(beta_init, br_tau, signal_template, mask=fit_data._decay_map['sig_twotau'])[0]\n",
    "                h_onetau  += fh.signal_mixture_model(beta_init, br_tau, signal_template, mask=fit_data._decay_map['sig_onetau'])[0]\n",
    "                h_nominal += fh.signal_mixture_model(beta_init, br_tau, signal_template)[0]\n",
    "                \n",
    "        h_nominal += h_bg\n",
    "        h_twotau += h_bg\n",
    "        h_onetau += h_twotau\n",
    "        \n",
    "        ax.plot(bins, h_bg/dx, drawstyle='steps-post', c='C3', linestyle='-', linewidth=2.)\n",
    "        ax.plot(bins, h_twotau/dx, drawstyle='steps-post', c='xkcd:blue violet', linestyle='-', linewidth=2.)\n",
    "        ax.plot(bins, h_onetau/dx, drawstyle='steps-post', c='xkcd:royal blue', linestyle='-', linewidth=2.)\n",
    "        ax.plot(bins, h_nominal/dx, drawstyle='steps-post', c='xkcd:azure', linestyle='-', linewidth=2.)\n",
    "        \n",
    "        xmin, xmax = bins[0]-dx[0], bins[-2]+dx[-2]\n",
    "        ax.set_xlim(xmin, xmax)\n",
    "        #ax.set_ylim(0.01, 10.*np.max(h_nominal[0]/dx))\n",
    "        ax.set_yscale('log')\n",
    "        if j == 0 or (selection in ['etau', 'mutau'] and j == 1):\n",
    "            ax.set_title(plot_labels[selection][1])\n",
    "            \n",
    "        if b == 0:\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(r'Entries / 1 GeV ($\\sf N_{b jet} = 0$)')\n",
    "        elif b == 1:\n",
    "            ax.set_xlabel(plot_labels[selection][0])\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(r'Entries / 1 GeV ($\\sf N_{b jet} = 1$)')\n",
    "        elif b == 2:\n",
    "            ax.set_xlabel(plot_labels[selection][0])\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(r'Entries / 1 GeV ($\\sf N_{b jet} \\geq 2$)')\n",
    "        ax.grid()\n",
    "    \n",
    "    axes[0][-1].legend(['bg', r'2 $\\tau$', r'1 $\\tau$', r'0 $\\tau$', 'toy data'], fontsize=14)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('plots/toy_mc_example.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# nominal case\n",
    "cost_type = 'poisson'\n",
    "p_init = list(fit_data.get_params_init()) + 26*[1., ] # niceify this: nuisance parameters are initialized to 1\n",
    "p_init = np.array(p_init)\n",
    "fobj = partial(fit_data.objective, data=toy_data, cost_type=cost_type)\n",
    "stderr, corr = fh.calculate_covariance(fobj, p_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('precision', 3)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.set_option('display.max_columns', len(p_labels))\n",
    "pd.set_option('display.max_rows', len(p_labels))\n",
    "\n",
    "#print(result.x)\n",
    "#print(cov[0])\n",
    "pct_err = pd.DataFrame(100*stderr/p_init, index=p_labels, columns=['stderr'])\n",
    "df_corr = pd.DataFrame(corr, columns=p_labels, index=p_labels)\n",
    "pct_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr.to_latex('data/cov_table_full.tex')\n",
    "df_corr.to_csv('data/cov_table_full.csv')\n",
    "\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(1, 1, facecolor='white', figsize=(16, 12))\n",
    "sns.heatmap(df_corr, cmap='Spectral', ax=ax, cbar_kws={'label': r'correlation coefficient'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating individual contributions\n",
    "\n",
    "If we make the assumption that the uncertainties sum in quadrature (which they should really given all of the correlations), we can write the total uncertainty as,\n",
    "\n",
    "$$\n",
    "\\sigma_{total}^{2} = \\sigma_{stat}^{2} + \\sum_{i}\\sigma_{i,syst}^{2}\n",
    "$$\n",
    "\n",
    "From this we can write evaluate the contribution from a single systematic source as,\n",
    "\n",
    "$$\n",
    "\\sigma_{i,syst}^{2} = \\sigma_{total}^{2} - \\sigma_{stat}^{2} - \\sum_{j\\neq i}\\sigma_{j,syst}^{2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# n-1 uncertainties\n",
    "from tqdm import tqdm_notebook, trange\n",
    "\n",
    "def reduced_objective(p, i, j=None):\n",
    "    if j == None or j < i:\n",
    "        j = i\n",
    "        \n",
    "    p = np.concatenate([p[:i], (j - i + 1)*[1,], p[j:]])\n",
    "    return fit_data.objective(p, data=toy_data, cost_type=cost_type)\n",
    "\n",
    "# stat only\n",
    "fobj = partial(reduced_objective, i=4, j=len(p_init))\n",
    "stderr_stat = np.concatenate([fh.calculate_covariance(fobj, p_init[:4])[0], p_init[4:].size*[0.,]])\n",
    "\n",
    "errs = [stderr_stat]\n",
    "p_init = p_init\n",
    "for i in tqdm_notebook(range(4, len(p_init))):\n",
    "    fobj = partial(reduced_objective, i=i)\n",
    "    stderr, cov = fh.calculate_covariance(fobj, p_init[:-1])\n",
    "    \n",
    "    stderr = np.concatenate([stderr[:i], [0], stderr[i:]])\n",
    "    errs.append(stderr)\n",
    "    \n",
    "# full systematics\n",
    "fobj = partial(fit_data.objective, data=toy_data, cost_type=cost_type)\n",
    "stderr_nominal = fh.calculate_covariance(fobj, p_init)[0]\n",
    "errs.append(stderr_nominal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = pd.DataFrame(errs, columns=p_labels, index=['stat only'] + p_labels[4:] + ['full'])\n",
    "errs.divide(p_init/100, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_vars = errs.iloc[:,:4]**2\n",
    "var_stat = beta_vars.iloc[0]\n",
    "var_nom  = beta_vars.iloc[-1]\n",
    "\n",
    "for i in trange(1, beta_vars.shape[0] - 1):\n",
    "    beta_vars.iloc[i] = var_nom - beta_vars.iloc[i]\n",
    "    \n",
    "beta_errs = np.sqrt(beta_vars)\n",
    "100*beta_errs.divide(p_init[:4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "29px",
    "width": "251px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "49px",
    "left": "0px",
    "right": "1493.87px",
    "top": "90.9965px",
    "width": "242px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "widgets": {
   "state": {
    "012f8bbe2fdb410dae6e2cde9d7fe5cb": {
     "views": []
    },
    "080556076f174648bddf64f17a54c523": {
     "views": []
    },
    "0ad83b5f67484ae5b8fd8dd43ccc39bd": {
     "views": []
    },
    "15acd81a9adc493683d9b63813f000bf": {
     "views": []
    },
    "1840cb6fded848b4ae95ec8d3db15ab2": {
     "views": []
    },
    "1dd83f822e074642ae4255b15ee661cf": {
     "views": []
    },
    "1e71a878e6474912a0efc497ecc5d65b": {
     "views": []
    },
    "2022ed83777b4963b630b5c46239e218": {
     "views": []
    },
    "21c4c57bfc48495194663e6a4fbac488": {
     "views": []
    },
    "22c45c75435348c0b9501d493d69fdca": {
     "views": []
    },
    "2635f668a1af4a9db2642e705d7c73ff": {
     "views": []
    },
    "2ad5ddd9347e451b9290e5b4179ab9a2": {
     "views": []
    },
    "2c062b5778024117984822b63b0593d7": {
     "views": []
    },
    "2f5eab2f6fb24192b76a5ffe99195d44": {
     "views": []
    },
    "31632517325046e8b0cb62e4f4ed2480": {
     "views": []
    },
    "3562b97192ed4d42bbab17f77c290f6b": {
     "views": []
    },
    "38a7cc053723492b921cf9f084ed243c": {
     "views": []
    },
    "3b5750b20e1745879ca0f965aad7b614": {
     "views": []
    },
    "3f1cbabbe2694a9dabe3f1c2e09d0ee2": {
     "views": []
    },
    "3fab6a26a70c4238a668a46d4dc88bf6": {
     "views": []
    },
    "3fb3c7a25e954a4888996976fa107737": {
     "views": []
    },
    "415db64fbc574daea8457ab600392f09": {
     "views": []
    },
    "4463de406b4645a4b562fe7917380ff9": {
     "views": []
    },
    "487e5450b5a24507932709f1fa8f59c1": {
     "views": []
    },
    "48aba73013e74e71927f71d42fb44d14": {
     "views": []
    },
    "4a19ad30f77e4fe6a2c84c8b62378a47": {
     "views": []
    },
    "4bc83ff5270d41679d76d26cdded8313": {
     "views": []
    },
    "4bdd9dd5c5c64646a27fa9096851458b": {
     "views": []
    },
    "5014cd42705f45178d5e6eeffd70f119": {
     "views": []
    },
    "5259b340b68e4fdb97fb4eaf9d98d954": {
     "views": []
    },
    "5986ef5b605a42aca10bc5834529ee06": {
     "views": []
    },
    "5c1aa44589a140eb9709734c843abde6": {
     "views": []
    },
    "600cd9ca4f4c46d4ad6fe57df107675a": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "61fe369ebdd14eaa89de110f6186e6b7": {
     "views": []
    },
    "62ac836017ae47a38f8fde806c5ec9b7": {
     "views": []
    },
    "632ccbfabe91405aa1c5a77c9ea754db": {
     "views": []
    },
    "66175f618ea5472baac618f998d2c06c": {
     "views": []
    },
    "6647a620af034d26abcd327ae02364d4": {
     "views": []
    },
    "6752222d2cba43e18f344a8db7f99d24": {
     "views": []
    },
    "6b684ba1a7c24a35ba2df77016212904": {
     "views": []
    },
    "6cea898f4aca4f1e84601f843e337238": {
     "views": []
    },
    "6f8d1e87fd60462a89d693b2f3b5f007": {
     "views": []
    },
    "74078646a5eb4047b40370a0ab8b6b30": {
     "views": []
    },
    "745b0c79ff3040788ea952fce9c7d607": {
     "views": []
    },
    "757c9b805eb7445bac9a7f141f87e45f": {
     "views": []
    },
    "76ced68e19a742e8976dbfd4e8594a1a": {
     "views": []
    },
    "783bb5e7538d4d9d8315e2698024b353": {
     "views": []
    },
    "794993d66efe4ab29a8d35aad8cfe079": {
     "views": []
    },
    "8375e24bae7541528d7cdc0f379d1d4c": {
     "views": []
    },
    "8554945ec15041a7bf8004dbc3fc5f11": {
     "views": []
    },
    "878a34e26cce4f18bb8232a682ebe964": {
     "views": []
    },
    "8921a75116a549198eb7b7f4a24ab672": {
     "views": []
    },
    "909f4504f0b049bda8b641defa177062": {
     "views": []
    },
    "910b9d32a3fb45ec99da1f9df1add816": {
     "views": []
    },
    "9d15ce601cd34f0699b7a7a0ce1d17dc": {
     "views": []
    },
    "a26638c9fee247b3891aac027a0918cc": {
     "views": []
    },
    "a9d2bf44a3ad447bb3eecde71363c198": {
     "views": []
    },
    "ad366bf4c95f4cdba62d47ba9501efc9": {
     "views": []
    },
    "ad8e1842ec314a94b6ed4b62c4c0a450": {
     "views": []
    },
    "af525094db304d2a812ae1312b00889b": {
     "views": []
    },
    "b0697c4343da491f9a35bf02681dad8f": {
     "views": []
    },
    "b07ff307919e4268bc8bec8379c47a5d": {
     "views": []
    },
    "b0e85c726ca141079333afb27edc63d4": {
     "views": []
    },
    "bdcc1e5df7a8432b9f40d8249a46f90a": {
     "views": []
    },
    "be1065f37fa24e818d31c3bb075947a3": {
     "views": []
    },
    "c296c8df2f734e268c6c1204536e7142": {
     "views": []
    },
    "c4bfd3e447f0426da144b76abc202129": {
     "views": []
    },
    "cced93184d4445218a2b14567579333d": {
     "views": []
    },
    "d5bd2e4d5f85482e9345f3a7a69380d0": {
     "views": []
    },
    "d798fa64e8be4a7d9ec1cbeece3b1be9": {
     "views": []
    },
    "d7aec0d6d05f442b991ab40af944811d": {
     "views": []
    },
    "db469cea2c8e4180bf6890de80329c1d": {
     "views": []
    },
    "e671857510c54634b6f0fa55bf1fa228": {
     "views": []
    },
    "ebf52deafaf64b0c826533dafdf993c0": {
     "views": []
    },
    "ed1e5439da9c41199a7bbbda21b556f8": {
     "views": []
    },
    "f585cf5db5024280af5b567f0e4fd771": {
     "views": []
    },
    "f6ba8f8800af47adabed847063bda8db": {
     "views": []
    },
    "f9bae72f14e44705b5c38a3ddc69fee8": {
     "views": []
    }
   },
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
